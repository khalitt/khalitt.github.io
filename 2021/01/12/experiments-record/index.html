<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>experiments-record | null</title><meta name="keywords" content="noisy-labels"><meta name="author" content="Walter"><meta name="copyright" content="Walter"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Image单模态，LR设为0.1不可训练（不可行）并没有tanaka在joint optimization中提到的high learning rate能有助于不学习label noise 可以看到symmetric 0.4或者asymmetric 0.6在lr 0.1(10x)的情况下，准确率很差   symmetric noise 0.4，lr 0.1 vs lr 0.01    asymmet">
<meta property="og:type" content="article">
<meta property="og:title" content="experiments-record">
<meta property="og:url" content="https://khalitt.github.io/2021/01/12/experiments-record/index.html">
<meta property="og:site_name">
<meta property="og:description" content="Image单模态，LR设为0.1不可训练（不可行）并没有tanaka在joint optimization中提到的high learning rate能有助于不学习label noise 可以看到symmetric 0.4或者asymmetric 0.6在lr 0.1(10x)的情况下，准确率很差   symmetric noise 0.4，lr 0.1 vs lr 0.01    asymmet">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2021-01-12T04:41:49.000Z">
<meta property="article:modified_time" content="2021-02-01T04:39:32.375Z">
<meta property="article:author" content="Walter">
<meta property="article:tag" content="noisy-labels">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://khalitt.github.io/2021/01/12/experiments-record/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"5100G1WE6M","apiKey":"c2a0f74ed768aa33e0c961937aa244bc","indexName":"prob_khalitt_github_io2","hits":{"per_page":6},"languages":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}.","hits_stats":"${hits} results found in ${time} ms"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-02-01 12:39:32'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">48</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">43</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">20</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-musicW"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-musicW"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">experiments-record</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-01-12T04:41:49.000Z" title="Created 2021-01-12 12:41:49">2021-01-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-02-01T04:39:32.375Z" title="Updated 2021-02-01 12:39:32">2021-02-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/noisy-labels/">noisy-labels</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">9.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>50min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Image单模态，LR设为0-1不可训练（不可行）"><a href="#Image单模态，LR设为0-1不可训练（不可行）" class="headerlink" title="Image单模态，LR设为0.1不可训练（不可行）"></a>Image单模态，LR设为0.1不可训练（不可行）</h1><p><strong>并没有tanaka在joint optimization中提到的high learning rate能有助于不学习label noise</strong></p>
<p>可以看到symmetric 0.4或者asymmetric 0.6在lr 0.1(10x)的情况下，准确率很差</p>
<p><img src="/2021/01/12/experiments-record/image-20210112124443147.png" alt="image-20210112124443147"></p>
<ul>
<li>symmetric noise 0.4，lr 0.1 vs lr 0.01</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210112124654925.png" alt="image-20210112124654925"></p>
<ul>
<li>asymmetric 0.4 lr 0.1 vs lr 0.01</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210112124934367.png" alt="image-20210112124934367"></p>
<h2 id="LR设为0-05-0-005也不可行"><a href="#LR设为0-05-0-005也不可行" class="headerlink" title="LR设为0.05 0.005也不可行"></a>LR设为0.05 0.005也不可行</h2><ul>
<li>symmetric noise 0.4的情况下，对比可以看到0.1，0.05,0.005都不太行，只有0.01比较好</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210112142024373.png" alt="image-20210112142024373"></p>
<p>看loss也可以一开始的loss都是不太一样的，但是后面越训练越趋近</p>
<p><img src="/2021/01/12/experiments-record/image-20210112142103537.png" alt="image-20210112142103537"></p>
<h1 id="T-Revision-MNIST测试"><a href="#T-Revision-MNIST测试" class="headerlink" title="T Revision MNIST测试"></a>T Revision MNIST测试</h1><h2 id="symmetric-noise-0-4"><a href="#symmetric-noise-0-4" class="headerlink" title="symmetric noise 0.4"></a>symmetric noise 0.4</h2><h3 id="默认参数测试"><a href="#默认参数测试" class="headerlink" title="默认参数测试"></a>默认参数测试</h3><p>MNIST 默认<code>batch_size=128</code>来看，估计的还算比较准确</p>
<p><img src="/2021/01/12/experiments-record/image-20210112142453614.png" alt="image-20210112142453614"></p>
<h4 id="batch-size-12800-lr-0-1"><a href="#batch-size-12800-lr-0-1" class="headerlink" title="batch_size = 12800, lr = 0.1"></a><code>batch_size = 12800, lr = 0.1</code></h4><p>可以看到效果更差了，还是默认的参数比较好。<strong>而且也和估计前学习到的classifier有关</strong></p>
<p><img src="/2021/01/12/experiments-record/image-20210112144126932.png" alt="image-20210112144126932"></p>
<h2 id="asymmetric-noise-0-4"><a href="#asymmetric-noise-0-4" class="headerlink" title="asymmetric noise 0.4"></a>asymmetric noise 0.4</h2><h4 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Estimated transition matrix:
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span>.2138e-01, <span class="token number">2</span>.7854e-01, <span class="token number">3</span>.0262e-06, <span class="token number">3</span>.6738e-07, <span class="token number">1</span>.2981e-07, <span class="token number">5</span>.1001e-06,
         <span class="token number">1</span>.8148e-05, <span class="token number">3</span>.1714e-05, <span class="token number">1</span>.3197e-06, <span class="token number">1</span>.8157e-05<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">5</span>.7726e-04, <span class="token number">6</span>.2115e-01, <span class="token number">3</span>.7681e-01, <span class="token number">1</span>.3360e-04, <span class="token number">3</span>.5784e-04, <span class="token number">8</span>.6032e-05,
         <span class="token number">5</span>.3814e-05, <span class="token number">1</span>.9459e-04, <span class="token number">4</span>.5552e-04, <span class="token number">1</span>.8873e-04<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">9</span>.7088e-06, <span class="token number">8</span>.9477e-04, <span class="token number">6</span>.8011e-01, <span class="token number">3</span>.0870e-01, <span class="token number">6</span>.0487e-03, <span class="token number">1</span>.5677e-04,
         <span class="token number">2</span>.0933e-04, <span class="token number">3</span>.5460e-04, <span class="token number">3</span>.0163e-03, <span class="token number">4</span>.9286e-04<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>.3503e-05, <span class="token number">7</span>.5012e-05, <span class="token number">9</span>.7758e-04, <span class="token number">5</span>.4234e-01, <span class="token number">4</span>.5637e-01, <span class="token number">1</span>.6872e-04,
         <span class="token number">5</span>.0566e-05, <span class="token number">1</span>.7940e-07, <span class="token number">3</span>.3701e-06, <span class="token number">8</span>.3027e-06<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">4</span>.8065e-06, <span class="token number">9</span>.4964e-06, <span class="token number">6</span>.2487e-05, <span class="token number">3</span>.7153e-05, <span class="token number">7</span>.0554e-01, <span class="token number">2</span>.9411e-01,
         <span class="token number">1</span>.7484e-04, <span class="token number">4</span>.4826e-05, <span class="token number">8</span>.6875e-06, <span class="token number">5</span>.9524e-06<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">7</span>.3357e-05, <span class="token number">1</span>.3101e-05, <span class="token number">1</span>.3800e-06, <span class="token number">5</span>.4869e-05, <span class="token number">6</span>.3327e-04, <span class="token number">6</span>.3130e-01,
         <span class="token number">3</span>.6769e-01, <span class="token number">9</span>.2295e-05, <span class="token number">6</span>.4091e-05, <span class="token number">7</span>.0743e-05<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>.5855e-03, <span class="token number">8</span>.7621e-04, <span class="token number">3</span>.1088e-05, <span class="token number">7</span>.7596e-06, <span class="token number">6</span>.9697e-05, <span class="token number">2</span>.1452e-02,
         <span class="token number">6</span>.4550e-01, <span class="token number">3</span>.3030e-01, <span class="token number">6</span>.9375e-05, <span class="token number">1</span>.0396e-04<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">8</span>.1278e-04, <span class="token number">2</span>.3544e-04, <span class="token number">5</span>.0871e-05, <span class="token number">7</span>.7580e-05, <span class="token number">7</span>.5762e-05, <span class="token number">8</span>.7224e-04,
         <span class="token number">3</span>.7420e-04, <span class="token number">6</span>.6014e-01, <span class="token number">3</span>.3609e-01, <span class="token number">1</span>.2711e-03<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>.9071e-03, <span class="token number">3</span>.5230e-04, <span class="token number">2</span>.1717e-03, <span class="token number">9</span>.8912e-04, <span class="token number">1</span>.4255e-03, <span class="token number">3</span>.2609e-04,
         <span class="token number">2</span>.6533e-04, <span class="token number">1</span>.0653e-04, <span class="token number">6</span>.1251e-01, <span class="token number">3</span>.7995e-01<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">4</span>.0376e-01, <span class="token number">5</span>.3920e-07, <span class="token number">3</span>.7207e-07, <span class="token number">5</span>.6868e-06, <span class="token number">4</span>.2000e-04, <span class="token number">1</span>.2035e-04,
         <span class="token number">7</span>.1814e-07, <span class="token number">1</span>.5838e-04, <span class="token number">2</span>.0765e-04, <span class="token number">5</span>.9533e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span>
True transition matrix:
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
The estimation error is <span class="token number">0.11802714886404604</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p>总体还是估计的比较准</p>
<h1 id="T-Revision-CIFAR10测试"><a href="#T-Revision-CIFAR10测试" class="headerlink" title="T Revision CIFAR10测试"></a>T Revision CIFAR10测试</h1><h2 id="symmetric-noise-0-4-1"><a href="#symmetric-noise-0-4-1" class="headerlink" title="symmetric noise 0.4"></a>symmetric noise 0.4</h2><p>默认参数</p>
<ul>
<li>可以看到还是有一定的准确率的，至少能够保证对角线上的元素不会接近于1，但同时也是同一行最大的元素</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>       <span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>       <span class="token punctuation">]</span><span class="token punctuation">]</span>


Val Loss: <span class="token number">1.945421</span>, Acc: <span class="token number">0.431000</span>                                                                                                                                                                     <span class="token punctuation">[</span><span class="token number">0</span>/373<span class="token punctuation">]</span>
epoch <span class="token number">20</span>
Train Loss: <span class="token number">1.740070</span>, Acc: <span class="token number">0.479556</span>
Val Loss: <span class="token number">1.973744</span>, Acc: <span class="token number">0.431400</span>
Estimated transition matrix:
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.4469</span>, <span class="token number">0.0260</span>, <span class="token number">0.1041</span>, <span class="token number">0.0390</span>, <span class="token number">0.1306</span>, <span class="token number">0.0741</span>, <span class="token number">0.0450</span>, <span class="token number">0.0878</span>, <span class="token number">0.0115</span>,
         <span class="token number">0.0351</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0220</span>, <span class="token number">0.6145</span>, <span class="token number">0.0254</span>, <span class="token number">0.0339</span>, <span class="token number">0.0490</span>, <span class="token number">0.0716</span>, <span class="token number">0.0512</span>, <span class="token number">0.0372</span>, <span class="token number">0.0461</span>,
         <span class="token number">0.0492</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0606</span>, <span class="token number">0.0301</span>, <span class="token number">0.4259</span>, <span class="token number">0.0794</span>, <span class="token number">0.0816</span>, <span class="token number">0.0407</span>, <span class="token number">0.0582</span>, <span class="token number">0.0853</span>, <span class="token number">0.0927</span>,
         <span class="token number">0.0454</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0399</span>, <span class="token number">0.0185</span>, <span class="token number">0.0344</span>, <span class="token number">0.5259</span>, <span class="token number">0.0116</span>, <span class="token number">0.1639</span>, <span class="token number">0.0885</span>, <span class="token number">0.0600</span>, <span class="token number">0.0253</span>,
         <span class="token number">0.0321</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0338</span>, <span class="token number">0.0265</span>, <span class="token number">0.0805</span>, <span class="token number">0.0910</span>, <span class="token number">0.5191</span>, <span class="token number">0.0445</span>, <span class="token number">0.0589</span>, <span class="token number">0.0735</span>, <span class="token number">0.0252</span>,
         <span class="token number">0.0470</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0309</span>, <span class="token number">0.0330</span>, <span class="token number">0.0383</span>, <span class="token number">0.0972</span>, <span class="token number">0.0380</span>, <span class="token number">0.4335</span>, <span class="token number">0.0312</span>, <span class="token number">0.2013</span>, <span class="token number">0.0714</span>,
         <span class="token number">0.0252</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0274</span>, <span class="token number">0.0401</span>, <span class="token number">0.0219</span>, <span class="token number">0.0906</span>, <span class="token number">0.1141</span>, <span class="token number">0.0547</span>, <span class="token number">0.5203</span>, <span class="token number">0.0391</span>, <span class="token number">0.0442</span>,
         <span class="token number">0.0476</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0377</span>, <span class="token number">0.0196</span>, <span class="token number">0.0225</span>, <span class="token number">0.0213</span>, <span class="token number">0.0454</span>, <span class="token number">0.0261</span>, <span class="token number">0.0224</span>, <span class="token number">0.7676</span>, <span class="token number">0.0175</span>,
         <span class="token number">0.0199</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0248</span>, <span class="token number">0.0538</span>, <span class="token number">0.0659</span>, <span class="token number">0.0488</span>, <span class="token number">0.0559</span>, <span class="token number">0.0609</span>, <span class="token number">0.0244</span>, <span class="token number">0.0700</span>, <span class="token number">0.4952</span>,
         <span class="token number">0.1002</span><span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">0.0261</span>, <span class="token number">0.0160</span>, <span class="token number">0.0332</span>, <span class="token number">0.0479</span>, <span class="token number">0.0088</span>, <span class="token number">0.0322</span>, <span class="token number">0.0142</span>, <span class="token number">0.0486</span>, <span class="token number">0.0229</span>,
         <span class="token number">0.7501</span><span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span>
True transition matrix:
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span> <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>        <span class="token number">0.04444444</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span>
  <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.04444444</span> <span class="token number">0.6</span>       <span class="token punctuation">]</span><span class="token punctuation">]</span>
The estimation error is <span class="token number">0.32300532655583486</span>
Estimate finish<span class="token punctuation">..</span><span class="token punctuation">..</span>.Training<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="asymmetric-0-4"><a href="#asymmetric-0-4" class="headerlink" title="asymmetric 0.4"></a>asymmetric 0.4</h2><ul>
<li>默认参数</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Actual noise <span class="token number">0.40</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Actual noise <span class="token number">0.40</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Estimate transition matirx<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>Waiting<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>
epoch <span class="token number">1</span>


Train Loss: <span class="token number">1.020411</span>, Acc: <span class="token number">0.518000</span>
Val Loss: <span class="token number">1.220109</span>, Acc: <span class="token number">0.464000</span>
epoch <span class="token number">20</span>
Train Loss: <span class="token number">1.005580</span>, Acc: <span class="token number">0.521067</span>
Val Loss: <span class="token number">1.226898</span>, Acc: <span class="token number">0.463200</span>
Estimated transition matrix:
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span>.4242e-01, <span class="token number">2</span>.4246e-01, <span class="token number">2</span>.7850e-03, <span class="token number">8</span>.4317e-04, <span class="token number">4</span>.9211e-04, <span class="token number">5</span>.2459e-04,
         <span class="token number">1</span>.8819e-04, <span class="token number">7</span>.3340e-04, <span class="token number">4</span>.9761e-03, <span class="token number">4</span>.5775e-03<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">6</span>.8398e-04, <span class="token number">6</span>.4443e-01, <span class="token number">3</span>.5391e-01, <span class="token number">2</span>.6642e-05, <span class="token number">1</span>.2400e-05, <span class="token number">1</span>.3245e-05,
         <span class="token number">1</span>.8296e-04, <span class="token number">1</span>.0236e-04, <span class="token number">2</span>.1593e-04, <span class="token number">4</span>.2654e-04<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">3</span>.7985e-05, <span class="token number">5</span>.2442e-01, <span class="token number">4</span>.7549e-01, <span class="token number">2</span>.8910e-07, <span class="token number">3</span>.6711e-08, <span class="token number">6</span>.9056e-08,
         <span class="token number">1</span>.0048e-07, <span class="token number">3</span>.4097e-07, <span class="token number">4</span>.7454e-06, <span class="token number">4</span>.9120e-05<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">8</span>.2929e-03, <span class="token number">1</span>.5819e-03, <span class="token number">3</span>.0692e-02, <span class="token number">5</span>.7357e-01, <span class="token number">3</span>.0599e-01, <span class="token number">2</span>.9479e-02,
         <span class="token number">2</span>.8462e-02, <span class="token number">1</span>.5182e-02, <span class="token number">2</span>.5711e-03, <span class="token number">4</span>.1792e-03<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>.3662e-03, <span class="token number">1</span>.9915e-04, <span class="token number">7</span>.3622e-03, <span class="token number">1</span>.8071e-02, <span class="token number">5</span>.7474e-01, <span class="token number">3</span>.8528e-01,
         <span class="token number">9</span>.2216e-03, <span class="token number">3</span>.4835e-03, <span class="token number">2</span>.1991e-04, <span class="token number">5</span>.0631e-05<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>.0864e-03, <span class="token number">6</span>.3302e-04, <span class="token number">8</span>.7667e-03, <span class="token number">6</span>.2122e-02, <span class="token number">5</span>.6899e-02, <span class="token number">4</span>.8854e-01,
         <span class="token number">3</span>.3600e-01, <span class="token number">3</span>.4640e-02, <span class="token number">1</span>.1092e-02, <span class="token number">2</span>.2156e-04<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>.5093e-04, <span class="token number">8</span>.9852e-05, <span class="token number">1</span>.7349e-04, <span class="token number">4</span>.1022e-04, <span class="token number">3</span>.8422e-04, <span class="token number">1</span>.3375e-04,
         <span class="token number">6</span>.2308e-01, <span class="token number">3</span>.7530e-01, <span class="token number">1</span>.9503e-04, <span class="token number">8</span>.2571e-05<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">1</span>.1851e-03, <span class="token number">1</span>.3255e-03, <span class="token number">7</span>.4400e-04, <span class="token number">3</span>.6824e-04, <span class="token number">1</span>.6724e-03, <span class="token number">1</span>.8169e-03,
         <span class="token number">4</span>.6614e-04, <span class="token number">6</span>.3631e-01, <span class="token number">3</span>.5525e-01, <span class="token number">8</span>.6169e-04<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">3</span>.1831e-03, <span class="token number">1</span>.4675e-03, <span class="token number">2</span>.6400e-04, <span class="token number">5</span>.8988e-05, <span class="token number">7</span>.8735e-05, <span class="token number">3</span>.5662e-05,
         <span class="token number">1</span>.6588e-05, <span class="token number">1</span>.1765e-04, <span class="token number">6</span>.6807e-01, <span class="token number">3</span>.2671e-01<span class="token punctuation">]</span>,
        <span class="token punctuation">[</span><span class="token number">2</span>.4795e-01, <span class="token number">5</span>.7143e-02, <span class="token number">4</span>.9979e-02, <span class="token number">6</span>.4383e-06, <span class="token number">8</span>.2659e-07, <span class="token number">1</span>.5378e-06,
         <span class="token number">5</span>.9085e-06, <span class="token number">2</span>.6324e-06, <span class="token number">4</span>.2720e-05, <span class="token number">6</span>.4487e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>, <span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span>
True transition matrix:
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span> <span class="token number">0</span>. <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span> <span class="token number">0.4</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.4</span> <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0</span>.  <span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
The estimation error is <span class="token number">0.2717611408448902</span>
Estimate finish<span class="token punctuation">..</span><span class="token punctuation">..</span>.Training<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<h1 id="关于DMI"><a href="#关于DMI" class="headerlink" title="关于DMI"></a>关于DMI</h1><h2 id="无论是哪个任务，都需要在pretrain"><a href="#无论是哪个任务，都需要在pretrain" class="headerlink" title="无论是哪个任务，都需要在pretrain"></a>无论是哪个任务，都需要在pretrain</h2><p>参考 <a target="_blank" rel="noopener" href="https://github.com/Newbeeer/L_DMI/issues/11#issuecomment-655433642">Why bad performance without model pre-training?</a></p>
<p>作者的观点：</p>
<blockquote>
<p>Hi,</p>
<p>Sorry for the late response. It’s a very good question. My guess is that if we don’t pretrain and directly apply L_dmi for training, the gradient is exploded and it’s very hard to schedule the learning rate.</p>
<p>To illustrate this, the gradient to the matrix A under $L_dmi$ loss is : $\partial log(∣det(A)∣) =(A^{−1})^T$. <strong>Note that when we random intialize a classifiers, the $det(A)$ or $det(submatrix of A)$ is rathely small</strong>. It leads to very large elements in $(A^{−1})^T$. <strong>Hence the gradient explode</strong>.</p>
<p><strong>If we pretrain the model for a while, det(A) or det(submatrix of A) would be much more amendable.</strong></p>
<p>Thanks.</p>
<p>Yilun</p>
</blockquote>
<p>具体操作：</p>
<ol>
<li>把原来的noisy train set划分出一个noisy validation set，预训练和正式训练差不多的epoch数，然后<strong>保存在noisy/clean validation上最好的模型</strong></li>
<li>load 1中获得的模型，继续用DMI LOSS在同一的noisy validation set上训练，同样通过noisy/clean validation set筛选出“最好的”模型，在clean test set上学习。</li>
</ol>
<p>例如：</p>
<ol>
<li>在CIFAR10的实验中，用的是noisy validation</li>
<li>在Clothing 1M中，则是用的clean validation（50k clean training数据）</li>
</ol>
<h2 id="对DMI的尝试"><a href="#对DMI的尝试" class="headerlink" title="对DMI的尝试"></a>对DMI的尝试</h2><h3 id="symmetric-noise-0-4-pretrain-15-epochs"><a href="#symmetric-noise-0-4-pretrain-15-epochs" class="headerlink" title="symmetric noise 0.4 + pretrain 15 epochs"></a>symmetric noise 0.4 + pretrain 15 epochs</h3><ul>
<li>加载ckpt <code>/home/weitaotang/multimodal/results_temp/image_single_frame/models/ravdess_symmetric_image_single_frame_0.4_no_h_score/0111_180507_93108/checkpoint-epoch15.pth</code></li>
<li>SGD: lr 1e-07, mementum 0.9, weight_decay 1e-3</li>
</ul>
<p>可以看到总体来说是<strong>能够学习到clean的信息的</strong>：</p>
<ul>
<li>clean sample的frame accuracy比noisy sample的大</li>
<li>在validation set上的accuracy经过16个epoch的训练后两个点的提升</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210113221318924.png" alt="image-20210113221318924"></p>
<p>但是训练不是非常稳定，比如loss有所反弹：</p>
<p><img src="/2021/01/12/experiments-record/image-20210113221527155.png" alt="image-20210113221527155"></p>
<p><img src="/2021/01/12/experiments-record/image-20210113221541423.png" alt="image-20210113221541423"></p>
<h1 id="image-single-frame实验结果"><a href="#image-single-frame实验结果" class="headerlink" title="image single frame实验结果"></a>image single frame实验结果</h1><h2 id="symmetric"><a href="#symmetric" class="headerlink" title="symmetric"></a>symmetric</h2><ul>
<li>val frame acc</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119224313250.png" alt="image-20210119224313250"></p>
<ul>
<li>val sample acc</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119224336766.png" alt="image-20210119224336766"></p>
<h2 id="asymmetric"><a href="#asymmetric" class="headerlink" title="asymmetric"></a>asymmetric</h2><p><img src="/2021/01/12/experiments-record/image-20210119224436046.png" alt="image-20210119224436046"></p>
<p><img src="/2021/01/12/experiments-record/image-20210119224448660.png" alt="image-20210119224448660"></p>
<h1 id="audio实验结果"><a href="#audio实验结果" class="headerlink" title="audio实验结果"></a>audio实验结果</h1><ul>
<li>frame acc</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119223953152.png" alt="image-20210119223953152"></p>
<ul>
<li>val sample acc</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119224016383.png" alt="image-20210119224016383"></p>
<h1 id="复现MINIST的learn-clean-patterns-first的现象"><a href="#复现MINIST的learn-clean-patterns-first的现象" class="headerlink" title="复现MINIST的learn clean patterns first的现象"></a>复现MINIST的learn clean patterns first的现象</h1><p>一言蔽之：不是非常明显，很难像A closer look at … 中如此明显。MLP有所体现，<strong>CNN干脆就没有先上升后下降的趋势</strong></p>
<h2 id="2-layer-MLP"><a href="#2-layer-MLP" class="headerlink" title="2-layer  MLP"></a>2-layer  MLP</h2><ul>
<li>clean val</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119223835696.png" alt="image-20210119223835696"></p>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><ul>
<li>clean val</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119223658643.png" alt="image-20210119223658643"></p>
<h1 id="T-Revision-ravdess尝试"><a href="#T-Revision-ravdess尝试" class="headerlink" title="T Revision ravdess尝试"></a>T Revision ravdess尝试</h1><ul>
<li><p>总体来看，<strong>是有效果的</strong>，特别是单一模态时，error更小。因此可以考虑<strong>先单模态pretrain，再基于pretrain的结果进行训练</strong>！</p>
</li>
<li><p>除此之外，可以看到epoch较小时的checkpoint对应的T更准确，<strong>因此一开始pretrain不用太久！！</strong></p>
</li>
<li><p>symmetric总体估计得不如asymmetric准，可以<strong>推测noise rate越大越难估计（估计越不准）</strong></p>
</li>
</ul>
<p>实验设置：从epoch 5 ~ 30每5个epoch的ckpt载入，打印error最小的matrix以及对应的epoch checkpoint</p>
<h2 id="image"><a href="#image" class="headerlink" title="image"></a>image</h2><ul>
<li>trial 1</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>00:00,  <span class="token number">5</span>.97s/it<span class="token punctuation">]</span>
Found better revision t with err:0.392519 with ckpt:
/home/weitaotang/multimodal/results_temp/image_single_frame/models/ravdess_symmetric_noise_0.4_image_single_frame_no_h_score/0113_220659_93722/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span>.37014813e-01 <span class="token number">5</span>.49748095e-02 <span class="token number">1</span>.91551456e-02 <span class="token number">1</span>.06802471e-02
  <span class="token number">7</span>.75371623e-03 <span class="token number">1</span>.70421249e-01<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.49264102e-02 <span class="token number">7</span>.05651750e-01 <span class="token number">1</span>.33411816e-01 <span class="token number">2</span>.91340008e-02
  <span class="token number">7</span>.21719406e-02 <span class="token number">4</span>.47040626e-02<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.69836739e-01 <span class="token number">5</span>.79755422e-02 <span class="token number">5</span>.83608894e-01 <span class="token number">3</span>.76570563e-02
  <span class="token number">5</span>.09809138e-02 <span class="token number">9</span>.99408390e-02<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">5</span>.90787815e-03 <span class="token number">6</span>.60515847e-02 <span class="token number">3</span>.96423090e-04 <span class="token number">7</span>.94890272e-01
  <span class="token number">4</span>.54765739e-03 <span class="token number">1</span>.28206202e-01<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">5</span>.04207044e-02 <span class="token number">3</span>.06661356e-02 <span class="token number">6</span>.10200234e-02 <span class="token number">3</span>.16125759e-02
  <span class="token number">8</span>.15995386e-01 <span class="token number">1</span>.02851814e-02<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.68665471e-02 <span class="token number">2</span>.29821654e-01 <span class="token number">2</span>.43432482e-03 <span class="token number">6</span>.61020219e-02
  <span class="token number">1</span>.24099067e-02 <span class="token number">6</span>.72365573e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">9</span>&lt;</span>00:00,  <span class="token number">6</span>.30s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">6</span>.05s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">6</span>.06s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">6</span>.04s/it<span class="token punctuation">]</span>
--------------------------------------------------------------------------------
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">6</span>.07s/it<span class="token punctuation">]</span>
Found better revision t with err:0.077368 with ckpt:
/home/weitaotang/multimodal/results_temp/image_single_frame/models/ravdess_asymmetric_noise_0.4_image_single_frame_no_h_score/0114_014042_93722/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span>.99978390e-01 <span class="token number">4</span>.24855948e-08 <span class="token number">4</span>.22028800e-06 <span class="token number">7</span>.55608108e-09
  <span class="token number">1</span>.72387464e-05 <span class="token number">1</span>.00746411e-07<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">5</span>.97121342e-05 <span class="token number">6</span>.31816556e-01 <span class="token number">7</span>.50882308e-03 <span class="token number">3</span>.53185713e-01
  <span class="token number">6</span>.74934108e-03 <span class="token number">6</span>.79860689e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.92773897e-08 <span class="token number">2</span>.28556597e-05 <span class="token number">5</span>.49387958e-01 <span class="token number">1</span>.72671389e-05
  <span class="token number">4</span>.50389371e-01 <span class="token number">1</span>.82462852e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">3</span>.87757505e-06 <span class="token number">4</span>.13954102e-01 <span class="token number">5</span>.28141591e-04 <span class="token number">5</span>.85183560e-01
  <span class="token number">2</span>.97371327e-04 <span class="token number">3</span>.29412852e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.75910082e-07 <span class="token number">2</span>.36618023e-04 <span class="token number">2</span>.86706670e-01 <span class="token number">4</span>.47445345e-05
  <span class="token number">7</span>.12622216e-01 <span class="token number">3</span>.89617483e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.74123657e-04 <span class="token number">2</span>.17408124e-03 <span class="token number">8</span>.70988746e-04 <span class="token number">2</span>.19455221e-03
  <span class="token number">1</span>.13185740e-03 <span class="token number">9</span>.93454396e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">8</span>&lt;</span>00:00,  <span class="token number">6</span>.23s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">7</span>&lt;</span>00:00,  <span class="token number">6</span>.19s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>00:00,  <span class="token number">6</span>.40s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>01:5<span class="token operator"><span class="token file-descriptor important">7</span>&lt;</span>00:00,  <span class="token number">6</span>.17s/it<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<ul>
<li>trail 2</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">7</span>.14s/it<span class="token punctuation">]</span>
Found better revision t with err:0.340032 with ckpt:
/home/weitaotang/multimodal/results_temp/image_single_frame/models/ravdess_symmetric_noise_0.4_image_single_frame_no_h_score/0113_220659_93722/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.74072658</span> <span class="token number">0.01935282</span> <span class="token number">0.07026559</span> <span class="token number">0.00596408</span> <span class="token number">0.01678354</span> <span class="token number">0.14690741</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.03586634</span> <span class="token number">0.71411037</span> <span class="token number">0.12696856</span> <span class="token number">0.01515382</span> <span class="token number">0.02747697</span> <span class="token number">0.08042397</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.06790715</span> <span class="token number">0.15041716</span> <span class="token number">0.58079056</span> <span class="token number">0.05768638</span> <span class="token number">0.02814293</span> <span class="token number">0.1150558</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04842931</span> <span class="token number">0.04216269</span> <span class="token number">0.00557405</span> <span class="token number">0.80087784</span> <span class="token number">0.0454859</span>  <span class="token number">0.05747022</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.02076734</span> <span class="token number">0.08967834</span> <span class="token number">0.03257319</span> <span class="token number">0.02381871</span> <span class="token number">0.80996074</span> <span class="token number">0.02320168</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.05548994</span> <span class="token number">0.07312605</span> <span class="token number">0.01950351</span> <span class="token number">0.04691109</span> <span class="token number">0.12951871</span> <span class="token number">0.6754507</span> <span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">9</span>&lt;</span>00:00,  <span class="token number">6</span>.82s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">9</span>&lt;</span>00:00,  <span class="token number">6</span>.83s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">7</span>.06s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>00:00,  <span class="token number">6</span>.93s/it<span class="token punctuation">]</span>
--------------------------------------------------------------------------------
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>00:00,  <span class="token number">6</span>.98s/it<span class="token punctuation">]</span>
Found better revision t with err:0.071826 with ckpt:
/home/weitaotang/multimodal/results_temp/image_single_frame/models/ravdess_asymmetric_noise_0.4_image_single_frame_no_h_score/0114_014042_93722/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span>.99978176e-01 <span class="token number">8</span>.94074767e-08 <span class="token number">3</span>.23012549e-07 <span class="token number">1</span>.69097617e-07
  <span class="token number">3</span>.21461266e-07 <span class="token number">2</span>.09213347e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span>.55739884e-08 <span class="token number">6</span>.30913114e-01 <span class="token number">1</span>.07774438e-04 <span class="token number">3</span>.68945120e-01
  <span class="token number">3</span>.26208051e-05 <span class="token number">1</span>.32215717e-06<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">5</span>.65324598e-06 <span class="token number">7</span>.42724068e-03 <span class="token number">5</span>.52161788e-01 <span class="token number">4</span>.20391930e-03
  <span class="token number">4</span>.35413689e-01 <span class="token number">7</span>.87712614e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">4</span>.74741598e-06 <span class="token number">4</span>.17344832e-01 <span class="token number">2</span>.14540049e-04 <span class="token number">5</span>.82112667e-01
  <span class="token number">9</span>.40623789e-05 <span class="token number">2</span>.29176453e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">5</span>.60341346e-08 <span class="token number">3</span>.45309488e-04 <span class="token number">2</span>.88416076e-01 <span class="token number">1</span>.09513552e-04
  <span class="token number">7</span>.11108615e-01 <span class="token number">2</span>.04272590e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.81705001e-03 <span class="token number">2</span>.85893997e-03 <span class="token number">2</span>.13714621e-04 <span class="token number">1</span>.92421779e-03
  <span class="token number">2</span>.76464435e-04 <span class="token number">9</span>.92909613e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>00:00,  <span class="token number">6</span>.88s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">7</span>.17s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">9</span>&lt;</span>00:00,  <span class="token number">7</span>.32s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">7</span>.20s/it<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="audio"><a href="#audio" class="headerlink" title="audio"></a>audio</h2><ul>
<li>trail 1</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">8</span>&lt;</span>00:00,  <span class="token number">1</span>.04it/s<span class="token punctuation">]</span>
Found better revision t with err:0.415975 with ckpt:
/home/weitaotang/multimodal/results_temp/audio/models/ravdess_symmetric_noise_0.4_audio_no_h_score/0113_215056_93711/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.25389571</span> <span class="token number">0.09228479</span> <span class="token number">0.20698934</span> <span class="token number">0.27409103</span> <span class="token number">0.09113397</span> <span class="token number">0.08160515</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.08750636</span> <span class="token number">0.51496097</span> <span class="token number">0.0436491</span>  <span class="token number">0.10722706</span> <span class="token number">0.17794909</span> <span class="token number">0.06870737</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.15156065</span> <span class="token number">0.07283055</span> <span class="token number">0.35790298</span> <span class="token number">0.07674008</span> <span class="token number">0.29612027</span> <span class="token number">0.04484543</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.24321621</span> <span class="token number">0.06782876</span> <span class="token number">0.12313364</span> <span class="token number">0.49200456</span> <span class="token number">0.04399101</span> <span class="token number">0.02982585</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.06249942</span> <span class="token number">0.11504411</span> <span class="token number">0.2359151</span>  <span class="token number">0.01695025</span> <span class="token number">0.52651856</span> <span class="token number">0.04307259</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.13342992</span> <span class="token number">0.10467964</span> <span class="token number">0.05116186</span> <span class="token number">0.06034019</span> <span class="token number">0.08603964</span> <span class="token number">0.56434879</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>00:00,  <span class="token number">1</span>.38it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>00:00,  <span class="token number">1</span>.40it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">7</span>&lt;</span>00:00,  <span class="token number">1</span>.09it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">1</span>.31it/s<span class="token punctuation">]</span>
--------------------------------------------------------------------------------
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>00:00,  <span class="token number">1</span>.40it/s<span class="token punctuation">]</span>
Found better revision t with err:0.128727 with ckpt:
/home/weitaotang/multimodal/results_temp/audio/models/ravdess_asymmetric_noise_0.4_audio_no_h_score/0113_232736_93711/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span>.94958350e-01 <span class="token number">1</span>.78187583e-03 <span class="token number">3</span>.13801594e-04 <span class="token number">1</span>.89794601e-03
  <span class="token number">9</span>.41193957e-04 <span class="token number">1</span>.06832134e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">7</span>.20291405e-03 <span class="token number">5</span>.80317192e-01 <span class="token number">8</span>.54483371e-04 <span class="token number">4</span>.06137146e-01
  <span class="token number">5</span>.16415342e-03 <span class="token number">3</span>.24093753e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">9</span>.26777205e-04 <span class="token number">2</span>.19786319e-04 <span class="token number">4</span>.24290703e-01 <span class="token number">1</span>.18924458e-04
  <span class="token number">5</span>.74408175e-01 <span class="token number">3</span>.56532273e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">9</span>.01317605e-02 <span class="token number">3</span>.95732577e-01 <span class="token number">2</span>.24156240e-06 <span class="token number">5</span>.10228427e-01
  <span class="token number">5</span>.46904859e-06 <span class="token number">3</span>.89954887e-03<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">3</span>.46361430e-04 <span class="token number">3</span>.27936719e-04 <span class="token number">3</span>.12342425e-01 <span class="token number">3</span>.77159894e-04
  <span class="token number">6</span>.86280551e-01 <span class="token number">3</span>.25555057e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.31755906e-03 <span class="token number">4</span>.51953487e-05 <span class="token number">8</span>.15807118e-04 <span class="token number">6</span>.51472547e-05
  <span class="token number">1</span>.80661353e-03 <span class="token number">9</span>.95949677e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">7</span>&lt;</span>00:00,  <span class="token number">1</span>.09it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">1</span>.19it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">1</span>.23it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">1</span>.17it/s<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<ul>
<li>trail 2</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">1</span>.17it/s<span class="token punctuation">]</span>
Found better revision t with err:0.478438 with ckpt:
/home/weitaotang/multimodal/results_temp/audio/models/ravdess_symmetric_noise_0.4_audio_no_h_score/0113_215056_93711/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.25386552</span> <span class="token number">0.02816301</span> <span class="token number">0.09211877</span> <span class="token number">0.6069223</span>  <span class="token number">0.01289129</span> <span class="token number">0.00603905</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.08574092</span> <span class="token number">0.52417734</span> <span class="token number">0.04768458</span> <span class="token number">0.10971049</span> <span class="token number">0.15698343</span> <span class="token number">0.07570327</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.21533155</span> <span class="token number">0.06798532</span> <span class="token number">0.35652673</span> <span class="token number">0.10144213</span> <span class="token number">0.12699098</span> <span class="token number">0.1317233</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.15600043</span> <span class="token number">0.18612409</span> <span class="token number">0.03740445</span> <span class="token number">0.48830468</span> <span class="token number">0.06292662</span> <span class="token number">0.06923976</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.06397119</span> <span class="token number">0.06777771</span> <span class="token number">0.29985431</span> <span class="token number">0.00756286</span> <span class="token number">0.52437398</span> <span class="token number">0.03645993</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.16910183</span> <span class="token number">0.04342578</span> <span class="token number">0.11727054</span> <span class="token number">0.06100427</span> <span class="token number">0.03611601</span> <span class="token number">0.57308157</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">1</span>.28it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">1</span>.32it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">1</span>.28it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">1</span>.17it/s<span class="token punctuation">]</span>
--------------------------------------------------------------------------------
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">1</span>.29it/s<span class="token punctuation">]</span>
Found better revision t with err:0.132613 with ckpt:
/home/weitaotang/multimodal/results_temp/audio/models/ravdess_asymmetric_noise_0.4_audio_no_h_score/0113_232736_93711/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span>.95695854e-01 <span class="token number">6</span>.25396754e-07 <span class="token number">4</span>.48640111e-04 <span class="token number">7</span>.03666878e-07
  <span class="token number">6</span>.73638844e-04 <span class="token number">3</span>.18053830e-03<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span>.93859078e-03 <span class="token number">5</span>.79728069e-01 <span class="token number">2</span>.81209447e-05 <span class="token number">4</span>.16929769e-01
  <span class="token number">2</span>.67289118e-04 <span class="token number">1</span>.08146436e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span>.07288345e-02 <span class="token number">1</span>.81161874e-02 <span class="token number">4</span>.22044809e-01 <span class="token number">1</span>.34290555e-02
  <span class="token number">5</span>.08058915e-01 <span class="token number">1</span>.76222138e-02<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.08152351e-02 <span class="token number">4</span>.81431427e-01 <span class="token number">2</span>.01069297e-04 <span class="token number">5</span>.06482765e-01
  <span class="token number">9</span>.92116654e-04 <span class="token number">7</span>.74050277e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">9</span>.88331764e-05 <span class="token number">9</span>.43107348e-03 <span class="token number">3</span>.02070525e-01 <span class="token number">3</span>.79505090e-03
  <span class="token number">6</span>.84582485e-01 <span class="token number">2</span>.20230922e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span>.28925497e-03 <span class="token number">4</span>.81048368e-04 <span class="token number">1</span>.09156753e-04 <span class="token number">7</span>.81982182e-04
  <span class="token number">1</span>.99329388e-04 <span class="token number">9</span>.96139228e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">1</span>.30it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">1</span>.30it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">1</span>.17it/s<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>00:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">1</span>.25it/s<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="fusion"><a href="#fusion" class="headerlink" title="fusion"></a>fusion</h2><ul>
<li>trail 1</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:2<span class="token operator"><span class="token file-descriptor important">7</span>&lt;</span>00:00,  <span class="token number">7</span>.78s/it<span class="token punctuation">]</span>
Found better revision t with err:0.245888 with ckpt:
/home/weitaotang/multimodal/results_temp/fusion_no_h_score/models/ravdess_symmetric_noise_0.4_fusion_no_h_score/0111_034422_93107/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.69146853</span> <span class="token number">0.04797358</span> <span class="token number">0.07543566</span> <span class="token number">0.0422144</span>  <span class="token number">0.0418038</span>  <span class="token number">0.10110403</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.06336676</span> <span class="token number">0.67239938</span> <span class="token number">0.04360678</span> <span class="token number">0.06516055</span> <span class="token number">0.06039333</span> <span class="token number">0.09507321</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.02475316</span> <span class="token number">0.22107349</span> <span class="token number">0.59225173</span> <span class="token number">0.08914785</span> <span class="token number">0.03218814</span> <span class="token number">0.04058563</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.11797382</span> <span class="token number">0.08672993</span> <span class="token number">0.0874175</span>  <span class="token number">0.56456794</span> <span class="token number">0.11069051</span> <span class="token number">0.03262029</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.08571974</span> <span class="token number">0.04161564</span> <span class="token number">0.08419766</span> <span class="token number">0.04760431</span> <span class="token number">0.70514424</span> <span class="token number">0.03571841</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.19450805</span> <span class="token number">0.11750432</span> <span class="token number">0.02888204</span> <span class="token number">0.01387309</span> <span class="token number">0.0077209</span>  <span class="token number">0.63751161</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">9</span>&lt;</span>00:00,  <span class="token number">6</span>.80s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
 <span class="token number">42</span>%<span class="token operator">|</span>███████████████████████████████████████████████████████████████████████▏                                                                                                 <span class="token operator">|</span> <span class="token number">8</span>/19 <span class="token punctuation">[</span>01:0<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>00:32,  <span class="token number">2</span>.97s/it<span class="token punctuation">]</span>
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">8</span>&lt;</span>00:00,  <span class="token number">6</span>.75s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">9</span>&lt;</span>00:00,  <span class="token number">6</span>.80s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">6</span>.55s/it<span class="token punctuation">]</span>
--------------------------------------------------------------------------------
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">6</span>.65s/it<span class="token punctuation">]</span>
Found better revision t with err:0.118717 with ckpt:
/home/weitaotang/multimodal/results_temp/fusion_no_h_score/models/ravdess_asymmetric_noise_0.4_fusion_no_h_score/0111_060526_93108/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span>.99985077e-01 <span class="token number">3</span>.33303029e-09 <span class="token number">1</span>.19833905e-05 <span class="token number">9</span>.64756076e-11
  <span class="token number">1</span>.57460504e-06 <span class="token number">1</span>.36118361e-06<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">9</span>.70278939e-03 <span class="token number">4</span>.84771640e-01 <span class="token number">4</span>.20865655e-03 <span class="token number">4</span>.39756108e-01
  <span class="token number">3</span>.93429270e-03 <span class="token number">5</span>.76265214e-02<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">5</span>.33318368e-03 <span class="token number">1</span>.10967220e-03 <span class="token number">6</span>.32902630e-01 <span class="token number">4</span>.49600731e-04
  <span class="token number">3</span>.57397716e-01 <span class="token number">2</span>.80720290e-03<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">7</span>.46599467e-07 <span class="token number">2</span>.64882552e-01 <span class="token number">4</span>.20716284e-05 <span class="token number">7</span>.35061120e-01
  <span class="token number">6</span>.29869710e-06 <span class="token number">7</span>.20326376e-06<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">4</span>.85154986e-05 <span class="token number">1</span>.44868214e-03 <span class="token number">3</span>.41783826e-01 <span class="token number">4</span>.48218386e-04
  <span class="token number">6</span>.56216939e-01 <span class="token number">5</span>.38136212e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.01609887e-03 <span class="token number">1</span>.56412889e-03 <span class="token number">1</span>.38539968e-04 <span class="token number">2</span>.01553172e-03
  <span class="token number">2</span>.38128770e-04 <span class="token number">9</span>.95027572e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>00:00,  <span class="token number">6</span>.98s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">7</span>.12s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">7</span>.08s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:1<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>00:00,  <span class="token number">6</span>.93s/it<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<ul>
<li>trail 2</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:4<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>00:00,  <span class="token number">8</span>.47s/it<span class="token punctuation">]</span>
Found better revision t with err:0.269013 with ckpt:
/home/weitaotang/multimodal/results_temp/fusion_no_h_score/models/ravdess_symmetric_noise_0.4_fusion_no_h_score/0111_034422_93107/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.69253284</span> <span class="token number">0.01924669</span> <span class="token number">0.16257553</span> <span class="token number">0.08773406</span> <span class="token number">0.01293883</span> <span class="token number">0.02497208</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.04376511</span> <span class="token number">0.67207418</span> <span class="token number">0.10325625</span> <span class="token number">0.03216256</span> <span class="token number">0.07928783</span> <span class="token number">0.06945408</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.07502832</span> <span class="token number">0.09878149</span> <span class="token number">0.58612365</span> <span class="token number">0.20223092</span> <span class="token number">0.02060406</span> <span class="token number">0.01723154</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.11923723</span> <span class="token number">0.04975081</span> <span class="token number">0.12028455</span> <span class="token number">0.56648084</span> <span class="token number">0.03154257</span> <span class="token number">0.11270397</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.07270622</span> <span class="token number">0.03229545</span> <span class="token number">0.12604801</span> <span class="token number">0.05031482</span> <span class="token number">0.70455036</span> <span class="token number">0.01408514</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.10690363</span> <span class="token number">0.08137329</span> <span class="token number">0.1370423</span>  <span class="token number">0.01977044</span> <span class="token number">0.01520107</span> <span class="token number">0.63970925</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:3<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>00:00,  <span class="token number">7</span>.99s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:3<span class="token operator"><span class="token file-descriptor important">8</span>&lt;</span>00:00,  <span class="token number">8</span>.36s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:4<span class="token operator"><span class="token file-descriptor important">4</span>&lt;</span>00:00,  <span class="token number">8</span>.68s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">6</span>.59s/it<span class="token punctuation">]</span>
--------------------------------------------------------------------------------
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">6</span>.68s/it<span class="token punctuation">]</span>
Found better revision t with err:0.121845 with ckpt:
/home/weitaotang/multimodal/results_temp/fusion_no_h_score/models/ravdess_asymmetric_noise_0.4_fusion_no_h_score/0111_060526_93108/checkpoint-epoch5.pth
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span>.99986581e-01 <span class="token number">6</span>.27810544e-08 <span class="token number">1</span>.22991693e-05 <span class="token number">1</span>.14747236e-08
  <span class="token number">9</span>.95566532e-07 <span class="token number">5</span>.01988354e-08<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">6</span>.52518578e-07 <span class="token number">4</span>.85241528e-01 <span class="token number">4</span>.11671817e-05 <span class="token number">5</span>.14657624e-01
  <span class="token number">3</span>.47765738e-05 <span class="token number">2</span>.42646967e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span>.75373673e-04 <span class="token number">3</span>.39331788e-07 <span class="token number">6</span>.35205075e-01 <span class="token number">1</span>.25685331e-08
  <span class="token number">3</span>.64508174e-01 <span class="token number">1</span>.10258772e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span>.24452450e-06 <span class="token number">2</span>.44520915e-01 <span class="token number">1</span>.56135444e-02 <span class="token number">7</span>.34597455e-01
  <span class="token number">5</span>.13995242e-03 <span class="token number">1</span>.26881283e-04<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">2</span>.60336132e-04 <span class="token number">7</span>.43004952e-04 <span class="token number">3</span>.45211557e-01 <span class="token number">1</span>.79845275e-04
  <span class="token number">6</span>.53511809e-01 <span class="token number">9</span>.34460413e-05<span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">4</span>.71479600e-03 <span class="token number">9</span>.33652473e-05 <span class="token number">5</span>.41087780e-05 <span class="token number">6</span>.36025079e-05
  <span class="token number">7</span>.86016301e-05 <span class="token number">9</span>.94995526e-01<span class="token punctuation">]</span><span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">6</span>.61s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">8</span>&lt;</span>00:00,  <span class="token number">6</span>.76s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">6</span>&lt;</span>00:00,  <span class="token number">6</span>.66s/it<span class="token punctuation">]</span>
noisy_train dataset with <span class="token number">24180</span> samples
<span class="token number">100</span>%<span class="token operator">|</span>████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████<span class="token operator">|</span> <span class="token number">19</span>/19 <span class="token punctuation">[</span>02:0<span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>00:00,  <span class="token number">6</span>.58s/it<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<h1 id="reuters-验证learn-clean-patterns-first"><a href="#reuters-验证learn-clean-patterns-first" class="headerlink" title="reuters 验证learn clean patterns first"></a>reuters 验证learn clean patterns first</h1><ul>
<li>总体上来说是有learn clean pattern first的现象的，因为<strong>可以看到在前5~10个epochs内，clean acc始终比nosiy acc高，且clean ce loss 始终比 nosiy ce loss 高</strong></li>
<li>因此可以考虑dividemix那一类方法</li>
</ul>
<h2 id="0模态"><a href="#0模态" class="headerlink" title="0模态"></a>0模态</h2><h2 id="01模态"><a href="#01模态" class="headerlink" title="01模态"></a>01模态</h2><ul>
<li>loss</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210115204346546.png" alt="image-20210115204346546"></p>
<ul>
<li>accuracy</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210115204521254.png" alt="image-20210115204521254"></p>
<h1 id="L2R-reuters尝试"><a href="#L2R-reuters尝试" class="headerlink" title="L2R reuters尝试"></a>L2R reuters尝试</h1><p>总体来看，<strong>用SGD优化</strong>的情况下是有效果的，在未调参的情况下能够对比baseline有4-5个点的提升乃至10个点的提升。但是观察曲线可以发现<strong>noisy acc始终还是在上升的，即仍然会对noisy samples过拟合，因此要尽快考虑regularization的方法比如mixup</strong></p>
<p><img src="/2021/01/12/experiments-record/image-20210119114745327.png" alt="image-20210119114745327"></p>
<p><img src="/2021/01/12/experiments-record/image-20210119114805972.png" alt="image-20210119114805972"></p>
<h2 id="对比-baseline"><a href="#对比-baseline" class="headerlink" title="对比 baseline"></a>对比 baseline</h2><ul>
<li>0.4</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119120427076.png" alt="image-20210119120427076"></p>
<p><img src="/2021/01/12/experiments-record/image-20210119120437196.png" alt="image-20210119120437196"></p>
<ul>
<li>0.6</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119120456236.png" alt="image-20210119120456236"></p>
<p><img src="/2021/01/12/experiments-record/image-20210119120508626.png" alt="image-20210119120508626"></p>
<ul>
<li>0.7</li>
</ul>
<p><img src="/2021/01/12/experiments-record/image-20210119120609912.png" alt="image-20210119120609912"></p>
<p><img src="/2021/01/12/experiments-record/image-20210119120627710.png" alt="image-20210119120627710"></p>
<h1 id="DivideMix"><a href="#DivideMix" class="headerlink" title="DivideMix"></a>DivideMix</h1><h2 id="sym-0-4"><a href="#sym-0-4" class="headerlink" title="sym 0.4"></a>sym 0.4</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-------------------------------------------------------------------------------------------------------------------------------------------------------------
Exp: reuters-balance-symmetric_0.4-dividemix-fusion_<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>-SGD_lr0.01-clean_val
         h_score  loss    loss_2 label_loss_1  loss    loss_1   entropy unlabeled_loss_1 unlabeled_loss_2    loss_2 label_loss_2    loss_1 duration  accuracy
           train valid     valid        train train     valid     valid            train            train     train        train     train    train     valid
epoch-25     NaN   NaN  <span class="token number">1.177624</span>     <span class="token number">0.777585</span>   NaN  <span class="token number">1.060939</span>  <span class="token number">0.767858</span>         <span class="token number">0.008861</span>         <span class="token number">0.011454</span>  <span class="token number">1.231793</span>     <span class="token number">0.860347</span>  <span class="token number">1.097191</span>  <span class="token number">19</span>.891s  <span class="token number">0.660138</span>

<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Best val epoch on run <span class="token number">2</span>:11, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.6828</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token number">3</span> runs avg accuracy: <span class="token number">0.6897</span>/0.0051. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.6914'</span>, <span class="token string">'0.6948'</span>, <span class="token string">'0.6828'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="sym-0-6"><a href="#sym-0-6" class="headerlink" title="sym 0.6"></a>sym 0.6</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-------------------------------------------------------------------------------------------------------------------------------------------------------------
Exp: reuters-balance-symmetric_0.6-dividemix-fusion_<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>-SGD_lr0.01-clean_val
           entropy  loss_1 h_score unlabeled_loss_2 label_loss_2    loss_2           label_loss_1  accuracy    loss_1 unlabeled_loss_1  loss duration  loss
             valid   train   train            train        train     valid     train        train     valid     valid            train train    train valid
epoch-25  <span class="token number">0.753669</span>  <span class="token number">1.4467</span>     NaN         <span class="token number">0.007444</span>      <span class="token number">0.23004</span>  <span class="token number">2.827142</span>  <span class="token number">1.358757</span>     <span class="token number">0.354897</span>  <span class="token number">0.165899</span>  <span class="token number">2.842674</span>         <span class="token number">0.016391</span>   NaN  <span class="token number">23</span>.219s   NaN

<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Best val epoch on run <span class="token number">2</span>:11, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.1672</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token number">3</span> runs avg accuracy: <span class="token number">0.3029</span>/0.0976. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.3931'</span>, <span class="token string">'0.3483'</span>, <span class="token string">'0.1672'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="sym-0-7"><a href="#sym-0-7" class="headerlink" title="sym 0.7"></a>sym 0.7</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-------------------------------------------------------------------------------------------------------------------------------------------------------------
Exp: reuters-balance-symmetric_0.7-dividemix-fusion_<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>-SGD_lr0.01-clean_val
           entropy    loss_1 h_score unlabeled_loss_2 label_loss_2    loss_2           label_loss_1  accuracy    loss_1 unlabeled_loss_1  loss duration  loss
             valid     train   train            train        train     valid     train        train     valid     valid            train train    train valid
epoch-25  <span class="token number">0.897166</span>  <span class="token number">1.642383</span>     NaN         <span class="token number">0.007334</span>     <span class="token number">0.228026</span>  <span class="token number">2.936547</span>  <span class="token number">1.381694</span>     <span class="token number">0.562114</span>  <span class="token number">0.167051</span>  <span class="token number">2.332163</span>         <span class="token number">0.029605</span>   NaN  <span class="token number">14</span>.290s   NaN

<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Best val epoch on run <span class="token number">2</span>:17, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.3069</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token number">3</span> runs avg accuracy: <span class="token number">0.3397</span>/0.0283. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.3759'</span>, <span class="token string">'0.3362'</span>, <span class="token string">'0.3069'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h1 id="IEG"><a href="#IEG" class="headerlink" title="IEG"></a>IEG</h1><h2 id="可能尝试的点（DONE）"><a href="#可能尝试的点（DONE）" class="headerlink" title="可能尝试的点（DONE）"></a>可能尝试的点（DONE）</h2><h3 id="无法augment的数据"><a href="#无法augment的数据" class="headerlink" title="无法augment的数据"></a>无法augment的数据</h3><ul>
<li>对于reuters这种难以augment的数据，主要会影响的点在于原版中的pseudo label部分，因此可以考虑：<ul>
<li>按照K=1的情况进行，即直接用iteration output作为pseudo label，然后也去除掉KL loss，剩下原来的四部分</li>
<li>类似于ICT这种用同一个batch内的unlabelled sample进行mixup然后算一个unsupervised loss，代替KL loss，这么做等价于5个loss中有三个mixup loss</li>
</ul>
</li>
<li>根据noisy student的观点：noise可以分为两类：input noise和model noise。前者主要指的是data augmentation，后者则是dropout和stochastic depth<ul>
<li>mixmatch及其变种中大多数是利用了data augmentation即input noise，但是很多数据比如像reuters这种直接提取好特征找不到元数据的数据集，是没办法直接进行augment的。</li>
<li>因此对于这种情况，只能考虑后面的model noise。但是显然model noise并不是对sample进行处理的，直接套并不现实。<strong>并且model noise和input noise在theory上是否等同？</strong>这个点也是需要考虑的。如果不等同，显然不是一个好主意。</li>
<li>mixmatch中用到的data augmentation大多数还是为了保证consistency regularization，而consistency regularization在ICT的文章中说的也挺清楚的，最核心要把握的点就是保证在low density region中的样本有consistency regularization，即small perturbation不会让模型的输出发生变化</li>
</ul>
</li>
</ul>
<h3 id="hard-weights和percentile的影响"><a href="#hard-weights和percentile的影响" class="headerlink" title="hard weights和percentile的影响"></a>hard weights和percentile的影响</h3><p>当前的实现是使用归一化后的weight（-min / max - min）来实现的，但是实际上<strong>可能更好的方式直接利用<code>torch.quantile</code>找出对应的分位数</strong>，然后用这个作为阈值直接去卡<code>weights</code>。当前实测两种方法筛选出来的样本有一定差异(7/256)，<strong>总体差异可能不是太大，待实验</strong></p>
<h2 id="注意TensorFlow的实现中是没有使用threshold的"><a href="#注意TensorFlow的实现中是没有使用threshold的" class="headerlink" title="注意TensorFlow的实现中是没有使用threshold的"></a>注意TensorFlow的实现中是没有使用threshold的</h2><p>原文中的Algorithm的step 4有提到说有一个threshold的设置，只有低于threshold的才认为是possibly mislabeled的samples，需要用guessed  labels去代替。但是注意看Appendix B，里面最后提到了：</p>
<blockquote>
<p>Algorithm 1 step 4 uses a weight threshold T to divide the training batch to possibly clean set and possibly mislabeled set. <strong>In our experiments, we find setting T to be highest is optimal in terms of training stability</strong>, i.e. <strong>all data is treated as possibly mislabeled</strong>, because it makes the batch size fixed to compute other losses that use data with pseudo labels  </p>
</blockquote>
<p>这里可以理解为：对于 Sec 4.4里面的两个CE loss，如果不是按照原文那样的设置，将会导致这两个loss对应的样本始终在变化，也即导致loss的大小可能变化地很剧烈。</p>
<p><strong>具体实验的时候还要具体考虑一下。可能需要还原回原文的设置</strong></p>
<h2 id="注意batch-size对meta-valid-data-loader的影响"><a href="#注意batch-size对meta-valid-data-loader的影响" class="headerlink" title="注意batch size对meta_valid_data_loader的影响"></a>注意batch size对<code>meta_valid_data_loader</code>的影响</h2><p>默认是使用下面这个<code>inf_loop</code>来实现无穷枚举</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">inf_loop</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">''' wrapper function for endless data loader. '''</span>
    <span class="token keyword">for</span> loader <span class="token keyword">in</span> repeat<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> <span class="token keyword">from</span> loader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>但这种方式有两个问题：</p>
<ol>
<li>由于默认<code>drop_last=False</code>，因此如果<code>len(dataset)</code>不能被<code>batch_size</code>整除，则<strong>最后一小部分会被单独取出</strong>（因为这里本质上就是不断把一个个batch从data_loader中循环取出）。导致<code>batch_size</code>不是恒定的。</li>
<li>如果整个<code>len(dataset)</code>默认就比<code>batch_size</code>小，则每次取出的batch必然都会比设定的<code>batch_size</code>小</li>
</ol>
<p>特别上面，下面这种做法在<code>meta_valid_data_loader.dataset</code>的大小比默认的<code>batch_size</code>小的时候，每次取出的<code>meta_data</code>必然是不足的；如果不能被整除，则末尾那个<code>meta_batch</code>的大小也不正常。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_data<span class="token punctuation">,</span> meta_data<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_loader<span class="token punctuation">,</span> self<span class="token punctuation">.</span>meta_valid_data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


<p>正确做法可以用类似下面这种思路：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">g</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    all_res <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> t <span class="token keyword">in</span> cycle<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>all_res<span class="token punctuation">)</span> <span class="token operator">>=</span> size<span class="token punctuation">:</span>
            <span class="token keyword">yield</span> all_res
            all_res <span class="token operator">=</span> <span class="token punctuation">[</span>t<span class="token punctuation">]</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            all_res<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
            
iter_1 <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>g<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>iter_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span>, <span class="token number">2</span>, <span class="token number">3</span>, <span class="token number">4</span>, <span class="token number">0</span>, <span class="token number">1</span>, <span class="token number">2</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token number">3</span>, <span class="token number">4</span>, <span class="token number">0</span>, <span class="token number">1</span>, <span class="token number">2</span>, <span class="token number">3</span>, <span class="token number">4</span>, <span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<p>这里需要做的是改一下merge的逻辑</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">inf_loop_v2</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">''' wrapper function for endless data loader. Fix batch_size bug for torch only'''</span>
    merged_batch <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>cycle<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            merged_batch <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            merged_batch <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>data<span class="token punctuation">,</span> cur_data<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> data<span class="token punctuation">,</span> cur_data <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>merged_batch<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> merged_batch<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">>=</span> batch_size<span class="token punctuation">:</span>
            return_data <span class="token operator">=</span> <span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span>batch_size<span class="token punctuation">]</span> <span class="token keyword">for</span> data <span class="token keyword">in</span> merged_batch<span class="token punctuation">]</span>
            <span class="token keyword">yield</span> return_data
            merged_batch <span class="token operator">=</span> <span class="token punctuation">[</span>data<span class="token punctuation">[</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> data <span class="token keyword">in</span> merged_batch<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<h2 id="unsupervised-loss中对probe-image的permutation操作"><a href="#unsupervised-loss中对probe-image的permutation操作" class="headerlink" title="unsupervised loss中对probe image的permutation操作"></a>unsupervised loss中对probe image的permutation操作</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">n_probe_to_mix <span class="token operator">=</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>aug_images<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
probe <span class="token operator">=</span> tf<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>probe_images<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
idx <span class="token operator">=</span> tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>categorical<span class="token punctuation">(</span>probe<span class="token punctuation">,</span> n_probe_to_mix<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>上面这段操作本质上应该是不需要的，推测的原因可能是<strong>为了MixMode中不同mixup操作方式</strong>的需要。故可以考虑保留</p>
<h2 id="augmented-samples的labels"><a href="#augmented-samples的labels" class="headerlink" title="augmented samples的labels"></a>augmented samples的labels</h2><p>总体来说都是和未增强前的samples共用label</p>
<ul>
<li>对于possibly clean samples来说，就是未增强前的label，即一个hard label</li>
<li>对于possibly mislabeled samples来说，就是用g，即一个soft label</li>
</ul>
<h2 id="pytorch实验尝试"><a href="#pytorch实验尝试" class="headerlink" title="pytorch实验尝试"></a>pytorch实验尝试</h2><h3 id="sym0-4"><a href="#sym0-4" class="headerlink" title="sym0.4"></a>sym0.4</h3><p>最好的尝试：固定<code>mis_threshold=1.1</code>即如原文那样</p>
<p><code>2021-01-26/16-47-27-None/</code> </p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
Best val epoch on run <span class="token number">0</span>:13, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.7655</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
<span class="token number">1</span> runs avg accuracy: <span class="token number">0.7655</span>/0.0000. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.7655'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p><code>2021-01-26/16-51-09-None</code></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Best val epoch on run <span class="token number">0</span>:18, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.7655</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token number">1</span> runs avg accuracy: <span class="token number">0.7655</span>/0.0000. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.7655'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p>尝试用动态<code>ce_factor</code>的方法：不太好，不如固定的</p>
<p><code>2021-01-26/19-51-01-None/</code></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">2021</span>-01-26/19-51-01-None/reuters_ieg_train.log:1619:<span class="token punctuation">[</span><span class="token number">2021</span>-01-26 <span class="token number">20</span>:03:53,889<span class="token punctuation">]</span><span class="token punctuation">[</span>base-trainer<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Best val epoch on run <span class="token number">0</span>:14, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.6948</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


<h3 id="sym-0-6-1"><a href="#sym-0-6-1" class="headerlink" title="sym 0.6"></a>sym 0.6</h3><p>同样是固定ce_factor</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">2021</span>-01-26/19-50-32-None/reuters_ieg_train.log:3923:<span class="token punctuation">[</span><span class="token number">2021</span>-01-26 <span class="token number">20</span>:24:25,578<span class="token punctuation">]</span><span class="token punctuation">[</span>base-trainer<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Best val epoch on run <span class="token number">0</span>:16, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.6241</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<h3 id="尝试fake-augment（两次mixup）"><a href="#尝试fake-augment（两次mixup）" class="headerlink" title="尝试fake augment（两次mixup）"></a>尝试fake augment（两次mixup）</h3><p><strong>效果不大</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Exp: reuters-balance-symmetric_0.4-ieg-meta_fusion_<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>-SGD_lr0.01-clean_val
          meta_acc weight_acc meta_loss  accuracy h_score unlabeled_loss      loss  eps_loss  <span class="token punctuation">..</span>.  ema_loss unlabeled_u_loss      loss unlabeled_kl_loss   eps_acc duration    w_loss unlabeled_l_loss
             train      train     train     valid   train          train     valid     train  <span class="token punctuation">..</span>.     valid            train     train             train     train    train     train            train
epoch-25  <span class="token number">0.004568</span>   <span class="token number">0.402382</span>  <span class="token number">0.035882</span>  <span class="token number">0.704598</span>     NaN       <span class="token number">2.032226</span>  <span class="token number">0.856156</span>  <span class="token number">0.713818</span>  <span class="token punctuation">..</span>.  <span class="token number">0.953503</span>         <span class="token number">0.343933</span>  <span class="token number">2.463873</span>           <span class="token number">0.00215</span>  <span class="token number">0.732781</span>  <span class="token number">41</span>.601s  <span class="token number">0.149475</span>         <span class="token number">0.310409</span>

<span class="token punctuation">[</span><span class="token number">1</span> rows x <span class="token number">17</span> columns<span class="token punctuation">]</span>

<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Best val epoch on run <span class="token number">0</span>:10, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.7534</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token number">1</span> runs avg accuracy: <span class="token number">0.7534</span>/0.0000. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.7534'</span><span class="token punctuation">]</span>
Save at /home/weitaotang/multimodal/pytorch_hydra_results_temp/debug/2021-01-27/16-15-34-None
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Exp: reuters-balance-symmetric_0.4-ieg-meta_fusion_<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>-SGD_lr0.01-clean_val
         unlabeled_l_loss duration     loss           unlabeled_loss h_score  meta_acc meta_loss  <span class="token punctuation">..</span>.   eps_acc    w_loss  eps_loss  ema_loss  accuracy weight_acc ema_accuracy unlabeled_u_loss
                    train    train    valid     train          train   train     train     train  <span class="token punctuation">..</span>.     train     train     train     valid     valid      train        valid            train
epoch-20         <span class="token number">0.454691</span>  <span class="token number">41</span>.396s  <span class="token number">0.78376</span>  <span class="token number">3.406944</span>       <span class="token number">2.877247</span>     NaN  <span class="token number">0.004635</span>  <span class="token number">0.035477</span>  <span class="token punctuation">..</span>.  <span class="token number">0.749871</span>  <span class="token number">0.152077</span>  <span class="token number">0.907316</span>  <span class="token number">0.982341</span>  <span class="token number">0.751724</span>   <span class="token number">0.402382</span>     <span class="token number">0.710345</span>         <span class="token number">0.479111</span>

<span class="token punctuation">[</span><span class="token number">1</span> rows x <span class="token number">17</span> columns<span class="token punctuation">]</span>

Normal model <span class="token builtin class-name">test</span> on <span class="token number">580</span> samples <span class="token operator">|</span> Acc <span class="token number">0.7431</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
Best val epoch on run <span class="token number">0</span>:20, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.7431</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
<span class="token number">1</span> runs avg accuracy: <span class="token number">0.7431</span>/0.0000. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.7431'</span><span class="token punctuation">]</span>
Save at /home/weitaotang/multimodal/pytorch_hydra_results_temp/debug/2021-01-27/16-40-22-None
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<h2 id="0128-调参记录：暂时是效果最好的，acc能到0-81637"><a href="#0128-调参记录：暂时是效果最好的，acc能到0-81637" class="headerlink" title="0128 调参记录：暂时是效果最好的，acc能到0.81637"></a>0128 调参记录：暂时是效果最好的，acc能到0.81637</h2><h1 id="IEG-DivideMix"><a href="#IEG-DivideMix" class="headerlink" title="IEG + DivideMix"></a>IEG + DivideMix</h1><h2 id="可能可以尝试的点"><a href="#可能可以尝试的点" class="headerlink" title="可能可以尝试的点"></a>可能可以尝试的点</h2><ul>
<li>inconsistency error？就是KL，不过不是minimize而是maximize</li>
</ul>
<h2 id="尝试1：-IEG-仅仅加入weighted-guessed-labels"><a href="#尝试1：-IEG-仅仅加入weighted-guessed-labels" class="headerlink" title="尝试1： IEG + 仅仅加入weighted guessed labels"></a>尝试1： IEG + 仅仅加入weighted guessed labels</h2><p>基本是IEG的底子，两个模型，同时是step-based的更新方式，计算所有loss都是用自己所挑选出来的那一份数据。区别在使用了weighted  labels作为最后的unlabelled部分的输出。</p>
<p><code>mis_threshold=1.1</code>因此默认所有samples都是unlabelled samples，因此直接使用<code>weighted_guess_labels</code>的时候能够很方便地直接相加</p>
<p>有一定效果（取平均，大概2-3个点）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
Best val epoch on run <span class="token number">0</span>:17, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.8121</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
<span class="token number">1</span> runs avg accuracy: <span class="token number">0.8121</span>/0.0000. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.8121'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p>核心代码部分：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">mis_logits_1<span class="token punctuation">,</span> mis_inputs_1<span class="token punctuation">,</span> all_c_inputs_1<span class="token punctuation">,</span> all_c_labels_1<span class="token punctuation">,</span> mis_idx_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_mis_c<span class="token punctuation">(</span>hard_weight_1<span class="token punctuation">,</span>
                                                                                        logits_1<span class="token punctuation">,</span>
                                                                                        inputs<span class="token punctuation">,</span>
                                                                                        meta_inputs_1<span class="token punctuation">,</span>
                                                                                        meta_clean_labels_1<span class="token punctuation">,</span>
                                                                                        labels<span class="token punctuation">)</span>
mis_logits_2<span class="token punctuation">,</span> mis_inputs_2<span class="token punctuation">,</span> all_c_inputs_2<span class="token punctuation">,</span> all_c_labels_2<span class="token punctuation">,</span> mis_idx_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_mis_c<span class="token punctuation">(</span>hard_weight_2<span class="token punctuation">,</span>
                                                                                        logits_2<span class="token punctuation">,</span>
                                                                                        inputs<span class="token punctuation">,</span>
                                                                                        meta_inputs_2<span class="token punctuation">,</span>
                                                                                        meta_clean_labels_2<span class="token punctuation">,</span>
                                                                                        labels<span class="token punctuation">)</span>	<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_weighted_guess_label</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_logits_1<span class="token punctuation">,</span> w1<span class="token punctuation">,</span> batch_logits_2<span class="token punctuation">,</span> w2<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># K = batch_logits.size(0)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># old_w1, old_w2 = w1.clone().detach(), w2.clone().detach()</span>
        invalid_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>logical_and<span class="token punctuation">(</span>w1 <span class="token operator">==</span> <span class="token number">0.0</span><span class="token punctuation">,</span> w2 <span class="token operator">==</span> <span class="token number">0.0</span><span class="token punctuation">)</span>
        w1<span class="token punctuation">[</span>invalid_index<span class="token punctuation">]</span><span class="token punctuation">,</span> w2<span class="token punctuation">[</span>invalid_index<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span>
        reweight_w1 <span class="token operator">=</span> <span class="token punctuation">(</span>w1 <span class="token operator">/</span> <span class="token punctuation">(</span>w1 <span class="token operator">+</span> w2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        reweight_w2 <span class="token operator">=</span> <span class="token punctuation">(</span>w2 <span class="token operator">/</span> <span class="token punctuation">(</span>w1 <span class="token operator">+</span> w2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># expected K x batch x num_feat</span>
        all_u_logits_1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>batch_logits_1<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        norm_logits_1 <span class="token operator">=</span> <span class="token punctuation">[</span>logit_norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> reweight_w1 <span class="token keyword">for</span> x <span class="token keyword">in</span> all_u_logits_1<span class="token punctuation">]</span>
        p_model_y_1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> logits <span class="token keyword">in</span> norm_logits_1<span class="token punctuation">]</span><span class="token punctuation">)</span>
        p_model_y_1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>p_model_y_1<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        all_u_logits_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span>batch_logits_2<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        norm_logits_2 <span class="token operator">=</span> <span class="token punctuation">[</span>logit_norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> reweight_w2 <span class="token keyword">for</span> x <span class="token keyword">in</span> all_u_logits_2<span class="token punctuation">]</span>
        p_model_y_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> logits <span class="token keyword">in</span> norm_logits_2<span class="token punctuation">]</span><span class="token punctuation">)</span>
        p_model_y_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>p_model_y_2<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        p_model_y <span class="token operator">=</span> reweight_w1 <span class="token operator">*</span> p_model_y_1 <span class="token operator">+</span> reweight_w2 <span class="token operator">*</span> p_model_y_2

        p_target <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>p_model_y<span class="token punctuation">,</span> <span class="token number">1.0</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>T<span class="token punctuation">)</span>
        p_target <span class="token operator">/=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>p_target<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> p_target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">ema_decay</span><span class="token punctuation">:</span> <span class="token number">0.999</span>
<span class="token key atrule">meta_momentum</span><span class="token punctuation">:</span> <span class="token number">0.9</span>
<span class="token key atrule">grad_eps_init</span><span class="token punctuation">:</span> <span class="token number">0.9</span>
<span class="token key atrule">ce_factor</span><span class="token punctuation">:</span> <span class="token number">9</span>
<span class="token key atrule">consistency_factor</span><span class="token punctuation">:</span> <span class="token number">20</span>
<span class="token key atrule">T</span><span class="token punctuation">:</span> <span class="token number">0.5</span>
<span class="token key atrule">beta</span><span class="token punctuation">:</span> <span class="token number">0.5</span>
<span class="token key atrule">meta_lr</span><span class="token punctuation">:</span> <span class="token number">1e-4</span>
<span class="token key atrule">mis_threshold</span><span class="token punctuation">:</span> <span class="token number">1.1</span> <span class="token comment"># 1.1 means treat all to be mislabel</span>

<span class="token key atrule">learning_rate</span><span class="token punctuation">:</span> <span class="token number">0.03</span>

<span class="token key atrule">use_fake_aug</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>
<span class="token key atrule">fake_aug_lambda</span><span class="token punctuation">:</span> <span class="token number">0.95</span>

<span class="token key atrule">use_scheduler</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>
<span class="token key atrule">use_penalty</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="尝试2：进一步交换二者信息"><a href="#尝试2：进一步交换二者信息" class="headerlink" title="尝试2：进一步交换二者信息"></a>尝试2：进一步交换二者信息</h2><p>效果差不多</p>
<p>参数设置同样设置<code>mis_threshold=1.1</code>（即<strong>最后两个<code>weighted_guessed_labels</code>是相同的</strong>），<code>ce_factor=5, learning_rate=0.01</code>，其实和尝试1是差不多的参数，发现效果和1其实差不多</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Exp: reuters-balance-symmetric_0.4-ieg_dividemix-meta_fusion_<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>-SGD_lr0.03-clean_val
            loss_2    loss_1               acc_1 eps_acc_1  w_loss_2 duration  accuracy  <span class="token punctuation">..</span>. unlabeled_loss_1 weight_acc_2 meta_loss_1  w_loss_1 meta_acc_1 unlabeled_l_loss_2 meta_acc_2 meta_loss_2
             valid     train     valid     valid     train     train    train     valid  <span class="token punctuation">..</span>.            train        train       train     train      train              train      train       train
epoch-20  <span class="token number">0.688819</span>  <span class="token number">6.708918</span>  <span class="token number">0.684294</span>  <span class="token number">0.777011</span>  <span class="token number">0.842914</span>  <span class="token number">0.302043</span>  <span class="token number">71</span>.749s  <span class="token number">0.793103</span>  <span class="token punctuation">..</span>.         <span class="token number">6.392279</span>     <span class="token number">0.402382</span>    <span class="token number">0.044373</span>  <span class="token number">0.337714</span>   <span class="token number">0.004645</span>           <span class="token number">0.376796</span>   <span class="token number">0.004645</span>    <span class="token number">0.033203</span>

<span class="token punctuation">[</span><span class="token number">1</span> rows x <span class="token number">30</span> columns<span class="token punctuation">]</span>

Test on <span class="token number">580</span> samples <span class="token operator">|</span> Merged acc <span class="token number">0.8052</span> <span class="token operator">|</span> Acc_1 <span class="token number">0.8000</span> <span class="token operator">|</span> Acc_2 <span class="token number">0.8000</span>
Saving current best with max accuracy/valid:0.7931: model_best.pth <span class="token punctuation">..</span>.
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
Best val epoch on run <span class="token number">0</span>:20, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.8052</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token number">1</span> runs avg accuracy: <span class="token number">0.8052</span>/0.0000. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.8052'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<p>核心代码如下：可以看到几乎整个输入都交换了</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">weight_1<span class="token punctuation">,</span> hard_weight_1<span class="token punctuation">,</span> eps_1<span class="token punctuation">,</span> meta_loss_1<span class="token punctuation">,</span> meta_acc_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>meta_optimize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">,</span> self<span class="token punctuation">.</span>optimizer<span class="token punctuation">,</span>
                                                                             meta_inputs_1<span class="token punctuation">,</span>
                                                                             meta_clean_labels_1<span class="token punctuation">,</span>
                                                                             labels<span class="token punctuation">,</span>
                                                                             inputs<span class="token punctuation">,</span>
                                                                             init_guessed_labels_1<span class="token punctuation">)</span>
weight_2<span class="token punctuation">,</span> hard_weight_2<span class="token punctuation">,</span> eps_2<span class="token punctuation">,</span> meta_loss_2<span class="token punctuation">,</span> meta_acc_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>meta_optimize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model2<span class="token punctuation">,</span>
                                                                             self<span class="token punctuation">.</span>optimizer2<span class="token punctuation">,</span>
                                                                             meta_inputs_2<span class="token punctuation">,</span>
                                                                             meta_clean_labels_2<span class="token punctuation">,</span>
                                                                             labels<span class="token punctuation">,</span>
                                                                             inputs<span class="token punctuation">,</span>
                                                                             init_guessed_labels_2<span class="token punctuation">)</span>
exchange <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token keyword">if</span> exchange<span class="token punctuation">:</span>
    weight_1<span class="token punctuation">,</span> weight_2 <span class="token operator">=</span> weight_2<span class="token punctuation">,</span> weight_1
    hard_weight_1<span class="token punctuation">,</span> hard_weight_2 <span class="token operator">=</span> hard_weight_2<span class="token punctuation">,</span> hard_weight_1

    meta_inputs_1<span class="token punctuation">,</span> meta_inputs_2 <span class="token operator">=</span> meta_inputs_2<span class="token punctuation">,</span> meta_inputs_1
    meta_clean_labels_1<span class="token punctuation">,</span> meta_clean_labels_2 <span class="token operator">=</span> meta_clean_labels_2<span class="token punctuation">,</span> meta_clean_labels_1

mis_logits_1<span class="token punctuation">,</span> mis_inputs_1<span class="token punctuation">,</span> all_c_inputs_1<span class="token punctuation">,</span> all_c_labels_1<span class="token punctuation">,</span> mis_idx_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_mis_c<span class="token punctuation">(</span>weight_1<span class="token punctuation">,</span>
                                                                                        hard_weight_1<span class="token punctuation">,</span>
                                                                                        logits_1<span class="token punctuation">,</span>
                                                                                        inputs<span class="token punctuation">,</span>
                                                                                        meta_inputs_1<span class="token punctuation">,</span>
                                                                                        meta_clean_labels_1<span class="token punctuation">,</span>
                                                                                        labels<span class="token punctuation">)</span>
mis_logits_2<span class="token punctuation">,</span> mis_inputs_2<span class="token punctuation">,</span> all_c_inputs_2<span class="token punctuation">,</span> all_c_labels_2<span class="token punctuation">,</span> mis_idx_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_mis_c<span class="token punctuation">(</span>weight_2<span class="token punctuation">,</span>
                                                                                        hard_weight_2<span class="token punctuation">,</span>
                                                                                        logits_2<span class="token punctuation">,</span>
                                                                                        inputs<span class="token punctuation">,</span>
                                                                                        meta_inputs_2<span class="token punctuation">,</span>
                                                                                        meta_clean_labels_2<span class="token punctuation">,</span>
                                                                                        labels<span class="token punctuation">)</span>

<span class="token comment"># TODO: try co_guessed_labels</span>
<span class="token comment"># co_guessed_labels = self._guess_label(torch.cat([logits_1, logits_2], 0))</span>

<span class="token comment"># weighted_guessed_labels = self._weighted_coguess_label(torch.unsqueeze(mis_logits_1, 0), weight_1,</span>
<span class="token comment">#                                                        torch.unsqueeze(mis_logits_2, 0), weight_2)</span>

weighted_guessed_labels_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>_weighted_single_guess_labels<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>mis_logits_1<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                               mis_idx_1<span class="token punctuation">,</span> weight_1<span class="token punctuation">,</span>
                                                               torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>logits_2<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                               weight_2<span class="token punctuation">)</span>
weighted_guessed_labels_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_weighted_single_guess_labels<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>mis_logits_2<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mis_idx_2<span class="token punctuation">,</span>
                                                               weight_2<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>logits_1<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                               weight_1<span class="token punctuation">)</span>
<span class="token keyword">assert</span> <span class="token punctuation">(</span>weighted_guessed_labels_1 <span class="token operator">==</span> weighted_guessed_labels_2<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

l_loss_1<span class="token punctuation">,</span> u_loss_1<span class="token punctuation">,</span> consistency_loss_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>single_unsupervised_loss<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">,</span> mis_logits_1<span class="token punctuation">,</span>
                                                                       mis_inputs_1<span class="token punctuation">,</span> all_c_inputs_1<span class="token punctuation">,</span>
                                                                       all_c_labels_1<span class="token punctuation">,</span>
                                                                       weighted_guessed_labels_1<span class="token punctuation">)</span>
l_loss_2<span class="token punctuation">,</span> u_loss_2<span class="token punctuation">,</span> consistency_loss_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>single_unsupervised_loss<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model2<span class="token punctuation">,</span> mis_logits_2<span class="token punctuation">,</span>
                                                                       mis_inputs_2<span class="token punctuation">,</span> all_c_inputs_2<span class="token punctuation">,</span>
                                                                       all_c_labels_2<span class="token punctuation">,</span>
                                                                       weighted_guessed_labels_2<span class="token punctuation">)</span>
<span class="token keyword">if</span> exchange<span class="token punctuation">:</span>
    weight_1<span class="token punctuation">,</span> weight_2 <span class="token operator">=</span> weight_2<span class="token punctuation">,</span> weight_1
w_loss_1<span class="token punctuation">,</span> eps_loss_1 <span class="token operator">=</span> self<span class="token punctuation">.</span>lambda_weight_loss<span class="token punctuation">(</span>logits_1<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> eps_1<span class="token punctuation">,</span> weight_1<span class="token punctuation">,</span>
                                               weighted_guessed_labels_1<span class="token punctuation">)</span>
w_loss_2<span class="token punctuation">,</span> eps_loss_2 <span class="token operator">=</span> self<span class="token punctuation">.</span>lambda_weight_loss<span class="token punctuation">(</span>logits_2<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> eps_2<span class="token punctuation">,</span> weight_2<span class="token punctuation">,</span>
                                               weighted_guessed_labels_2<span class="token punctuation">)</span>

un_loss_1 <span class="token operator">=</span> l_loss_1 <span class="token operator">+</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>ce_factor <span class="token operator">*</span> u_loss_1 <span class="token operator">+</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>consistency_factor <span class="token operator">*</span> consistency_loss_1
un_loss_2 <span class="token operator">=</span> l_loss_2 <span class="token operator">+</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>ce_factor <span class="token operator">*</span> u_loss_2 <span class="token operator">+</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>consistency_factor <span class="token operator">*</span> consistency_loss_2

loss_1 <span class="token operator">=</span> <span class="token punctuation">(</span>w_loss_1 <span class="token operator">+</span> eps_loss_1<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">.</span> <span class="token operator">+</span> un_loss_1
loss_2 <span class="token operator">=</span> <span class="token punctuation">(</span>w_loss_2 <span class="token operator">+</span> eps_loss_2<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">.</span> <span class="token operator">+</span> un_loss_2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<h2 id="bug-1：RuntimeError-cannot-sample-n-sample-lt-0-samples"><a href="#bug-1：RuntimeError-cannot-sample-n-sample-lt-0-samples" class="headerlink" title="bug 1：RuntimeError: cannot sample n_sample &lt;= 0 samples"></a>bug 1：RuntimeError: cannot sample n_sample &lt;= 0 samples</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:
  File <span class="token string">"/home/weitaotang/.conda/envs/multimodal/lib/python3.7/site-packages/hydra/_internal/utils.py"</span>, line <span class="token number">347</span>, <span class="token keyword">in</span> _run_hydra
    lambda: hydra.run<span class="token punctuation">(</span>
  File <span class="token string">"/home/weitaotang/.conda/envs/multimodal/lib/python3.7/site-packages/hydra/_internal/utils.py"</span>, line <span class="token number">201</span>, <span class="token keyword">in</span> run_and_report
    raise ex
  File <span class="token string">"/home/weitaotang/.conda/envs/multimodal/lib/python3.7/site-packages/hydra/_internal/utils.py"</span>, line <span class="token number">198</span>, <span class="token keyword">in</span> run_and_report
    <span class="token builtin class-name">return</span> func<span class="token punctuation">(</span><span class="token punctuation">)</span>
  File <span class="token string">"/home/weitaotang/.conda/envs/multimodal/lib/python3.7/site-packages/hydra/_internal/utils.py"</span>, line <span class="token number">350</span>, <span class="token keyword">in</span> <span class="token operator">&lt;</span>lambda<span class="token operator">></span>
    <span class="token assign-left variable">overrides</span><span class="token operator">=</span>args.overrides,
  File <span class="token string">"/home/weitaotang/.conda/envs/multimodal/lib/python3.7/site-packages/hydra/_internal/hydra.py"</span>, line <span class="token number">112</span>, <span class="token keyword">in</span> run
    <span class="token assign-left variable">configure_logging</span><span class="token operator">=</span>with_log_configuration,
  File <span class="token string">"/home/weitaotang/.conda/envs/multimodal/lib/python3.7/site-packages/hydra/core/utils.py"</span>, line <span class="token number">128</span>, <span class="token keyword">in</span> run_job
    ret.return_value <span class="token operator">=</span> task_function<span class="token punctuation">(</span>task_cfg<span class="token punctuation">)</span>
  File <span class="token string">"srcs/entry_points/reuters_ieg_dividemix_train.py"</span>, line <span class="token number">145</span>, <span class="token keyword">in</span> main
    res <span class="token operator">=</span> trainer.train<span class="token punctuation">(</span><span class="token punctuation">)</span>
  File <span class="token string">"/home/weitaotang/multimodal/hydra_templates/srcs/trainer/base.py"</span>, line <span class="token number">99</span>, <span class="token keyword">in</span> train
    result <span class="token operator">=</span> self._train_epoch<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
  File <span class="token string">"/home/weitaotang/multimodal/hydra_templates/srcs/trainer/reuters_ieg_dividemix_trainer.py"</span>, line <span class="token number">197</span>, <span class="token keyword">in</span> _train_epoch
    weighted_guessed_labels_1<span class="token punctuation">)</span>
  File <span class="token string">"/home/weitaotang/multimodal/hydra_templates/srcs/trainer/reuters_ieg_dividemix_trainer.py"</span>, line <span class="token number">338</span>, <span class="token keyword">in</span> single_unsupervised_loss
    idx <span class="token operator">=</span> m.sample<span class="token variable"><span class="token punctuation">((</span>mis_logits.size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">))</span></span>
  File <span class="token string">"/home/weitaotang/.conda/envs/multimodal/lib/python3.7/site-packages/torch/distributions/categorical.py"</span>, line <span class="token number">107</span>, <span class="token keyword">in</span> sample
    samples_2d <span class="token operator">=</span> torch.multinomial<span class="token punctuation">(</span>probs_2d, sample_shape.numel<span class="token punctuation">(</span><span class="token punctuation">)</span>, True<span class="token punctuation">)</span>.T
RuntimeError: cannot sample n_sample <span class="token operator">&lt;</span><span class="token operator">=</span> <span class="token number">0</span> samples<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">HYDRA_FULL_ERROR</span><span class="token operator">=</span><span class="token number">1</span> python srcs/entry_points/reuters_ieg_dividemix_train.py <span class="token assign-left variable">status</span><span class="token operator">=</span>debug <span class="token assign-left variable">re_split_ratio</span><span class="token operator">=</span><span class="token number">1.0</span> <span class="token assign-left variable">mis_threshold</span><span class="token operator">=</span><span class="token number">0.2</span> <span class="token assign-left variable">learning_rate</span><span class="token operator">=</span><span class="token number">0.005</span> <span class="token assign-left variable">ce_factor</span><span class="token operator">=</span><span class="token number">9</span> <span class="token assign-left variable">meta_momentum</span><span class="token operator">=</span><span class="token number">0.9</span> <span class="token assign-left variable">meta_lr</span><span class="token operator">=</span><span class="token number">0.001</span> exchange_weigh
<span class="token assign-left variable">ts</span><span class="token operator">=</span>True <span class="token assign-left variable">noise_rate</span><span class="token operator">=</span><span class="token number">0.4</span> <span class="token assign-left variable">val_type</span><span class="token operator">=</span>clean <span class="token assign-left variable">use_penalty</span><span class="token operator">=</span>True trainer.save_ckpt<span class="token operator">=</span>False trainer.epochs<span class="token operator">=</span><span class="token number">25</span> trainer.test_on_best<span class="token operator">=</span>True <span class="token assign-left variable">n_splits</span><span class="token operator">=</span><span class="token number">2</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<p>查看发现是因为 <strong><code>mis_threshold</code>太小，导致分位点恰好是最小值</strong>，因此是不存在比他小的idx，也就导致了<code>mis_logits</code>为empty tensor。导致<code>sample_shape.numel()=0</code></p>
<p>一个可以考虑的方法：拿不到<code>idx</code>时取等</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_get_mis_c</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> weights<span class="token punctuation">,</span> hard_weight<span class="token punctuation">,</span> logits<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> meta_inputs<span class="token punctuation">,</span> meta_clean_labels<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_method <span class="token operator">==</span> <span class="token string">"hard_weights"</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_threshold <span class="token operator">>=</span> <span class="token number">1.0</span><span class="token punctuation">:</span>
        mis_idx <span class="token operator">=</span> hard_weight <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_threshold
        <span class="token keyword">if</span> mis_idx<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment"># 拿不到idx时取等</span>
            mis_idx <span class="token operator">=</span> hard_weight <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_threshold
    <span class="token keyword">elif</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_method <span class="token operator">==</span> <span class="token string">"quantile"</span><span class="token punctuation">:</span>
        mis_idx <span class="token operator">=</span> weights <span class="token operator">&lt;</span> torch<span class="token punctuation">.</span>quantile<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_threshold<span class="token punctuation">)</span>
        <span class="token keyword">if</span> mis_idx<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            mis_idx <span class="token operator">=</span> weights <span class="token operator">&lt;=</span> torch<span class="token punctuation">.</span>quantile<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_threshold<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Invalid mislabeled samples judgment method:</span><span class="token interpolation"><span class="token punctuation">&#123;</span>self<span class="token punctuation">.</span>config<span class="token punctuation">.</span>mis_method<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h1 id="每个batch都进行hard-weights或者weights-sum-to-1其实不是非常合理"><a href="#每个batch都进行hard-weights或者weights-sum-to-1其实不是非常合理" class="headerlink" title="每个batch都进行hard weights或者weights sum to 1其实不是非常合理"></a>每个batch都进行hard weights或者weights sum to 1其实不是非常合理</h1><p>强行把整个<code>weights</code> normalized到<code>[0, 1]</code>区间其实不合理，然后再按照一定的值进行截取（hard cut），会导致一定会有那么多数量的样本认为是clean，但是实际上是存在说整个batch都是noisy samples的情况。</p>
<p>同理把weights sum to 1，只是稍微好点，比如全部的samples的权重都比较小，此时强行让其sum to 1，就会使得有一部分的weight相对于原来有所增加。</p>
<p>可能比较好的做法是把所有weights都收集起来之后再进行normalized</p>
<h1 id="Hydra复现"><a href="#Hydra复现" class="headerlink" title="Hydra复现"></a>Hydra复现</h1><p>在代码不变的情况下，<strong>直接载入config文件，才能保证一致</strong></p>
<p>比如下面这种方式，直接载入保存的config文件：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token decorator annotation punctuation">@hydra<span class="token punctuation">.</span>main</span><span class="token punctuation">(</span>
    config_path<span class="token operator">=</span><span class="token string">'/home/weitaotang/multimodal/pytorch_hydra_results_temp/multirun/2021-02-01/01-00-04-dividemix_tuning_sym0.6_rerun/26_reuters-balance-symmetric_0.6-dividemix-optuna-fusion_N_[0, 1]-SGD_lr0.02-clean_val'</span><span class="token punctuation">,</span>
    config_name<span class="token operator">=</span><span class="token string">'config'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>原来的实验：</p>
<p><img src="/2021/01/12/experiments-record/image-20210201114803059.png" alt="image-20210201114803059"></p>
<p>复现的实验结果：</p>
<p><img src="/2021/01/12/experiments-record/image-20210201114823154.png" alt="image-20210201114823154"></p>
<p>但是缺点就是还要单独定制输出的文件夹，否则会很难看，比如下面这个实验就是会直接保存到当前目录的<code>outputs</code>下面</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span><span class="token number">2021</span>-02-01 <span class="token number">11</span>:39:25,075<span class="token punctuation">]</span><span class="token punctuation">[</span>base-trainer<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Exp: reuters-balance-symmetric_0.6-dividemix-optuna-fusion_N_<span class="token punctuation">[</span><span class="token number">0</span>, <span class="token number">1</span><span class="token punctuation">]</span>-SGD_lr0.02-clean_val
<span class="token punctuation">[</span><span class="token number">2021</span>-02-01 <span class="token number">11</span>:39:25,115<span class="token punctuation">]</span><span class="token punctuation">[</span>base-trainer<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> -           loss unlabeled_loss_2  accuracy unlabeled_loss_1   loss_2 label_loss_2 duration    loss_2   entropy h_score label_loss_1  loss    loss_1
         train            train     valid            train    valid        train    train     train     valid   train        train valid     valid     train
epoch-25   NaN         <span class="token number">0.005178</span>  <span class="token number">0.542002</span>         <span class="token number">0.005377</span>  <span class="token number">1.43616</span>     <span class="token number">0.751425</span>  <span class="token number">28</span>.738s  <span class="token number">0.979027</span>  <span class="token number">0.949788</span>     NaN     <span class="token number">0.784438</span>   NaN  <span class="token number">1.546014</span>  <span class="token number">1.011149</span>

<span class="token punctuation">[</span><span class="token number">2021</span>-02-01 <span class="token number">11</span>:39:25,119<span class="token punctuation">]</span><span class="token punctuation">[</span>base-trainer<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token operator">=</span>
<span class="token punctuation">[</span><span class="token number">2021</span>-02-01 <span class="token number">11</span>:39:25,119<span class="token punctuation">]</span><span class="token punctuation">[</span>base-trainer<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Best val epoch on run <span class="token number">1</span>:14, <span class="token builtin class-name">test</span> accuracy: <span class="token number">0.6448</span>
<span class="token punctuation">[</span><span class="token number">2021</span>-02-01 <span class="token number">11</span>:39:25,119<span class="token punctuation">]</span><span class="token punctuation">[</span>base-trainer<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token operator">=</span>
<span class="token punctuation">[</span><span class="token number">2021</span>-02-01 <span class="token number">11</span>:39:25,814<span class="token punctuation">]</span><span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - <span class="token number">2</span> runs avg accuracy: <span class="token number">0.6198</span>/0.0250. Each run <span class="token builtin class-name">test</span> accuracy:
<span class="token punctuation">[</span><span class="token string">'0.5948'</span>, <span class="token string">'0.6448'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token number">2021</span>-02-01 <span class="token number">11</span>:39:25,815<span class="token punctuation">]</span><span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">[</span>INFO<span class="token punctuation">]</span> - Save at /home/weitaotang/multimodal/hydra_templates/outputs/2021-02-01/10-59-35
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p>如果<strong>直接使用超参，效果是一样的</strong>，不过就是要单独配置参数，稍微有点麻烦</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">HYDRA_FULL_ERROR</span><span class="token operator">=</span><span class="token number">1</span> python srcs/entry_points/reuters_dividemix_train.py <span class="token assign-left variable">status</span><span class="token operator">=</span>train   <span class="token assign-left variable">warm_up_epochs</span><span class="token operator">=</span><span class="token number">8</span> <span class="token assign-left variable">p_threshold</span><span class="token operator">=</span><span class="token number">0.6000000000000001</span> <span class="token assign-left variable">alpha</span><span class="token operator">=</span><span class="token number">4</span> <span class="token assign-left variable">lambda_u</span><span class="token operator">=</span><span class="token number">30</span> <span class="token assign-left variable">weight_decay</span><span class="token operator">=</span>1e-05 <span class="token assign-left variable">learning_rate</span><span class="token operator">=</span><span class="token number">0.02</span> <span class="token assign-left variable">fusion</span><span class="token operator">=</span>sum <span class="token assign-left variable">rank</span><span class="token operator">=</span><span class="token number">3</span> <span class="token assign-left variable">noise_rate</span><span class="token operator">=</span><span class="token number">0.6</span> <span class="token assign-left variable">val_type</span><span class="token operator">=</span>clean trainer.save_ckpt<span class="token operator">=</span>False trainer.epochs<span class="token operator">=</span><span class="token number">25</span> trainer.test_on_best<span class="token operator">=</span>True <span class="token assign-left variable">notes</span><span class="token operator">=</span>dividemix_tuning_sym0.6_rerun <span class="token assign-left variable">n_splits</span><span class="token operator">=</span><span class="token number">2</span> <span class="token assign-left variable">model</span><span class="token operator">=</span>reuters_fusion_N
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/2021/01/12/experiments-record/image-20210201120439696.png" alt="image-20210201120439696"></p>
<p><code>/home/weitaotang/multimodal/pytorch_hydra_results_temp/train/2021-02-01/12-09-21-dividemix_tuning_sym0.6_rerun/config.yaml</code></p>
<p><img src="/2021/01/12/experiments-record/image-20210201123821296.png" alt="image-20210201123821296"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Walter</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://khalitt.github.io/2021/01/12/experiments-record/">https://khalitt.github.io/2021/01/12/experiments-record/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/noisy-labels/">noisy-labels</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/01/13/problems-record/ipython-hanging/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">ipython无法启动</div></div></a></div><div class="next-post pull-right"><a href="/2021/01/08/pytorch-meta-learning/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">pytorch-meta-learning</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Image%E5%8D%95%E6%A8%A1%E6%80%81%EF%BC%8CLR%E8%AE%BE%E4%B8%BA0-1%E4%B8%8D%E5%8F%AF%E8%AE%AD%E7%BB%83%EF%BC%88%E4%B8%8D%E5%8F%AF%E8%A1%8C%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">Image单模态，LR设为0.1不可训练（不可行）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#LR%E8%AE%BE%E4%B8%BA0-05-0-005%E4%B9%9F%E4%B8%8D%E5%8F%AF%E8%A1%8C"><span class="toc-number">1.1.</span> <span class="toc-text">LR设为0.05 0.005也不可行</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#T-Revision-MNIST%E6%B5%8B%E8%AF%95"><span class="toc-number">2.</span> <span class="toc-text">T Revision MNIST测试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#symmetric-noise-0-4"><span class="toc-number">2.1.</span> <span class="toc-text">symmetric noise 0.4</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E5%8F%82%E6%95%B0%E6%B5%8B%E8%AF%95"><span class="toc-number">2.1.1.</span> <span class="toc-text">默认参数测试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#batch-size-12800-lr-0-1"><span class="toc-number">2.1.1.1.</span> <span class="toc-text">batch_size &#x3D; 12800, lr &#x3D; 0.1</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#asymmetric-noise-0-4"><span class="toc-number">2.2.</span> <span class="toc-text">asymmetric noise 0.4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E5%8F%82%E6%95%B0"><span class="toc-number">2.2.0.1.</span> <span class="toc-text">默认参数</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#T-Revision-CIFAR10%E6%B5%8B%E8%AF%95"><span class="toc-number">3.</span> <span class="toc-text">T Revision CIFAR10测试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#symmetric-noise-0-4-1"><span class="toc-number">3.1.</span> <span class="toc-text">symmetric noise 0.4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#asymmetric-0-4"><span class="toc-number">3.2.</span> <span class="toc-text">asymmetric 0.4</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B3%E4%BA%8EDMI"><span class="toc-number">4.</span> <span class="toc-text">关于DMI</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E8%AE%BA%E6%98%AF%E5%93%AA%E4%B8%AA%E4%BB%BB%E5%8A%A1%EF%BC%8C%E9%83%BD%E9%9C%80%E8%A6%81%E5%9C%A8pretrain"><span class="toc-number">4.1.</span> <span class="toc-text">无论是哪个任务，都需要在pretrain</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9DMI%E7%9A%84%E5%B0%9D%E8%AF%95"><span class="toc-number">4.2.</span> <span class="toc-text">对DMI的尝试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#symmetric-noise-0-4-pretrain-15-epochs"><span class="toc-number">4.2.1.</span> <span class="toc-text">symmetric noise 0.4 + pretrain 15 epochs</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#image-single-frame%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">5.</span> <span class="toc-text">image single frame实验结果</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#symmetric"><span class="toc-number">5.1.</span> <span class="toc-text">symmetric</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#asymmetric"><span class="toc-number">5.2.</span> <span class="toc-text">asymmetric</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#audio%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">6.</span> <span class="toc-text">audio实验结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%8D%E7%8E%B0MINIST%E7%9A%84learn-clean-patterns-first%E7%9A%84%E7%8E%B0%E8%B1%A1"><span class="toc-number">7.</span> <span class="toc-text">复现MINIST的learn clean patterns first的现象</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-layer-MLP"><span class="toc-number">7.1.</span> <span class="toc-text">2-layer  MLP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CNN"><span class="toc-number">7.2.</span> <span class="toc-text">CNN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#T-Revision-ravdess%E5%B0%9D%E8%AF%95"><span class="toc-number">8.</span> <span class="toc-text">T Revision ravdess尝试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#image"><span class="toc-number">8.1.</span> <span class="toc-text">image</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#audio"><span class="toc-number">8.2.</span> <span class="toc-text">audio</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#fusion"><span class="toc-number">8.3.</span> <span class="toc-text">fusion</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#reuters-%E9%AA%8C%E8%AF%81learn-clean-patterns-first"><span class="toc-number">9.</span> <span class="toc-text">reuters 验证learn clean patterns first</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0%E6%A8%A1%E6%80%81"><span class="toc-number">9.1.</span> <span class="toc-text">0模态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#01%E6%A8%A1%E6%80%81"><span class="toc-number">9.2.</span> <span class="toc-text">01模态</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#L2R-reuters%E5%B0%9D%E8%AF%95"><span class="toc-number">10.</span> <span class="toc-text">L2R reuters尝试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94-baseline"><span class="toc-number">10.1.</span> <span class="toc-text">对比 baseline</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DivideMix"><span class="toc-number">11.</span> <span class="toc-text">DivideMix</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#sym-0-4"><span class="toc-number">11.1.</span> <span class="toc-text">sym 0.4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sym-0-6"><span class="toc-number">11.2.</span> <span class="toc-text">sym 0.6</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sym-0-7"><span class="toc-number">11.3.</span> <span class="toc-text">sym 0.7</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#IEG"><span class="toc-number">12.</span> <span class="toc-text">IEG</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%83%BD%E5%B0%9D%E8%AF%95%E7%9A%84%E7%82%B9%EF%BC%88DONE%EF%BC%89"><span class="toc-number">12.1.</span> <span class="toc-text">可能尝试的点（DONE）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E6%B3%95augment%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-number">12.1.1.</span> <span class="toc-text">无法augment的数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hard-weights%E5%92%8Cpercentile%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">12.1.2.</span> <span class="toc-text">hard weights和percentile的影响</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8FTensorFlow%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%B8%AD%E6%98%AF%E6%B2%A1%E6%9C%89%E4%BD%BF%E7%94%A8threshold%E7%9A%84"><span class="toc-number">12.2.</span> <span class="toc-text">注意TensorFlow的实现中是没有使用threshold的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8Fbatch-size%E5%AF%B9meta-valid-data-loader%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">12.3.</span> <span class="toc-text">注意batch size对meta_valid_data_loader的影响</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#unsupervised-loss%E4%B8%AD%E5%AF%B9probe-image%E7%9A%84permutation%E6%93%8D%E4%BD%9C"><span class="toc-number">12.4.</span> <span class="toc-text">unsupervised loss中对probe image的permutation操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#augmented-samples%E7%9A%84labels"><span class="toc-number">12.5.</span> <span class="toc-text">augmented samples的labels</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pytorch%E5%AE%9E%E9%AA%8C%E5%B0%9D%E8%AF%95"><span class="toc-number">12.6.</span> <span class="toc-text">pytorch实验尝试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sym0-4"><span class="toc-number">12.6.1.</span> <span class="toc-text">sym0.4</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sym-0-6-1"><span class="toc-number">12.6.2.</span> <span class="toc-text">sym 0.6</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%9D%E8%AF%95fake-augment%EF%BC%88%E4%B8%A4%E6%AC%A1mixup%EF%BC%89"><span class="toc-number">12.6.3.</span> <span class="toc-text">尝试fake augment（两次mixup）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#0128-%E8%B0%83%E5%8F%82%E8%AE%B0%E5%BD%95%EF%BC%9A%E6%9A%82%E6%97%B6%E6%98%AF%E6%95%88%E6%9E%9C%E6%9C%80%E5%A5%BD%E7%9A%84%EF%BC%8Cacc%E8%83%BD%E5%88%B00-81637"><span class="toc-number">12.7.</span> <span class="toc-text">0128 调参记录：暂时是效果最好的，acc能到0.81637</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#IEG-DivideMix"><span class="toc-number">13.</span> <span class="toc-text">IEG + DivideMix</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%83%BD%E5%8F%AF%E4%BB%A5%E5%B0%9D%E8%AF%95%E7%9A%84%E7%82%B9"><span class="toc-number">13.1.</span> <span class="toc-text">可能可以尝试的点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%9D%E8%AF%951%EF%BC%9A-IEG-%E4%BB%85%E4%BB%85%E5%8A%A0%E5%85%A5weighted-guessed-labels"><span class="toc-number">13.2.</span> <span class="toc-text">尝试1： IEG + 仅仅加入weighted guessed labels</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%9D%E8%AF%952%EF%BC%9A%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BA%A4%E6%8D%A2%E4%BA%8C%E8%80%85%E4%BF%A1%E6%81%AF"><span class="toc-number">13.3.</span> <span class="toc-text">尝试2：进一步交换二者信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bug-1%EF%BC%9ARuntimeError-cannot-sample-n-sample-lt-0-samples"><span class="toc-number">13.4.</span> <span class="toc-text">bug 1：RuntimeError: cannot sample n_sample &lt;&#x3D; 0 samples</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%AF%8F%E4%B8%AAbatch%E9%83%BD%E8%BF%9B%E8%A1%8Chard-weights%E6%88%96%E8%80%85weights-sum-to-1%E5%85%B6%E5%AE%9E%E4%B8%8D%E6%98%AF%E9%9D%9E%E5%B8%B8%E5%90%88%E7%90%86"><span class="toc-number">14.</span> <span class="toc-text">每个batch都进行hard weights或者weights sum to 1其实不是非常合理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hydra%E5%A4%8D%E7%8E%B0"><span class="toc-number">15.</span> <span class="toc-text">Hydra复现</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Walter</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/algolia.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>